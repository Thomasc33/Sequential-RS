{"cells":[{"cell_type":"markdown","metadata":{"id":"vuZfOZbmLpss"},"source":["## Codes"]},{"cell_type":"markdown","metadata":{"id":"oxR7uS3JrKQg"},"source":["### import"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37611,"status":"ok","timestamp":1683141801424,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"bKRpTOVnQw7U","outputId":"ac7497c1-0b87-4773-a5f2-664ac69e361c"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import random\n","import pickle\n","\n","import collections\n","from collections import defaultdict, Counter\n","\n","import scipy.sparse as sp\n","from sklearn.metrics import ndcg_score, dcg_score\n","\n","\n","from time import time\n","import os\n","# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n","\n","import tensorflow as tf\n","import tensorflow_probability as tfp\n","tfd = tfp.distributions\n","tfpl = tfp.layers\n","\n","# from tensorflow.keras import backend as K\n","from tensorflow import keras\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","import argparse\n","tf.config.run_functions_eagerly(True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1443,"status":"ok","timestamp":1683141802853,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"ekLfGIwBbKDD","outputId":"24392e98-4c4f-4984-b5cf-91666a4e2820"},"outputs":[],"source":["# %cd '/content/drive/My Drive/Colab Notebooks'\n","# %ls"]},{"cell_type":"markdown","metadata":{"id":"4hXqSm2prWb9"},"source":["### utils"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1683141802854,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"gIn2Jhs77u9d"},"outputs":[],"source":["def parse_args():\n","    parser = argparse.ArgumentParser(description=\"Run GMF.\")\n","    parser.add_argument('--path', nargs='?', default='data/',\n","                        help='Input data path.')\n","    parser.add_argument('--dataset', nargs='?', default='ml-1m',\n","                        help='Choose a dataset.')\n","    parser.add_argument('--nnModel', nargs='?', default='NextItNet_DistributedWeights', #[NextItNet_DistributedWeights, Bert4Rec]\n","                        help='Choose a recommender system model.')\n","    parser.add_argument('--mode', type=int, default=1,\n","                        help='Enter which uncertainty model is training')\n","    parser.add_argument('--seqlen', type=int, default=100,\n","                        help='Enter Sequence Length.')\n","    parser.add_argument('--T', type=int, default=10,\n","                        help='Enter T.')\n","    parser.add_argument('--tarlen', type=int, default=1,\n","                        help='Enter Target Length.')\n","    parser.add_argument('--setseed', type=int, default=2022,\n","                        help='Set a seed for random generator.')\n","    parser.add_argument('--max_epochs', type=int, default=10,\n","                        help='Number of epochs.')\n","    parser.add_argument('--embed_dims', type=int, default=32,\n","                        help='Embedding Dimension')\n","    parser.add_argument('--residual_channels', type=int, default=32,\n","                        help='CNN Residual Channels')\n","    parser.add_argument('--kernel_size', type=int, default=3,\n","                        help='CNN Kernel Size')\n","    parser.add_argument('--dilations', type=int, default=[1, 2, 4],\n","                        help='CNN Dilations')\n","    parser.add_argument('--batch_size', type=int, default=256,\n","                        help='Batch size.')\n","    parser.add_argument('--num_factors', type=int, default=8,\n","                        help='Embedding size.')\n","    parser.add_argument('--regs', nargs='?', default='[0,0]',\n","                        help=\"Regularization for user and item embeddings.\")\n","    parser.add_argument('--num_neg', type=int, default=4,\n","                        help='Number of negative instances to pair with a positive instance.')\n","    parser.add_argument('--lr', type=float, default=0.001,\n","                        help='Learning rate.')\n","    parser.add_argument('--learner', nargs='?', default='adam',\n","                        help='Specify an optimizer: adagrad, adam, rmsprop, sgd')\n","    parser.add_argument('--verbose', type=int, default=1,\n","                        help='Show performance per X iterations')\n","    parser.add_argument('--out', type=int, default=1,\n","                        help='Whether to save the trained model.')\n","    return parser.parse_known_args()\n","\n","args, __ = parse_args()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1683141802855,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"lS4kjzGT9gqi"},"outputs":[],"source":["# utils.py\n","\n","def set_seed(seed, cuda=False):\n","\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","set_seed(2023)"]},{"cell_type":"markdown","metadata":{"id":"mE17eI6YrQDD"},"source":["### Interactions"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1683141802855,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"EYZu6wJm8hNq"},"outputs":[],"source":["# args.path = '/content/drive/My Drive/Colab Notebooks/UncertaintyProject/data/'\n","args.path = ''\n","args.dataset = 'ml-100k'"]},{"cell_type":"markdown","metadata":{"id":"bgALY2UIlsOU"},"source":["\n","### Instance Spliter"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1683141802856,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"U3LMjr7y-C5f"},"outputs":[],"source":["class Instances:\n","    def __init__(self, name=''):\n","        self.name=name\n","        self.sequences = []\n","        self.ratings = []\n","        self.users = []\n","        self.targets = []  # movie ids\n","\n","    def shuffle(self):\n","        shuffle_indices = np.arange(len(self.sequences))\n","        np.random.shuffle(shuffle_indices)\n","\n","        self.sequences = self.sequences[shuffle_indices]\n","        self.ratings = self.ratings[shuffle_indices]\n","        self.users = self.users[shuffle_indices]\n","        self.targets = self.targets[shuffle_indices]\n","\n","\n","    def pprint(self):\n","        print('Data Instances Shape:', self.name, end='\\n')\n","        print('Sequences:', self.sequences.shape, 'Users:', self.users.shape, 'Targets:', self.targets.shape, 'Ratings:', self.ratings.shape)\n","\n","class Interactions:\n","    def __init__(self, args):\n","        self.args = args\n","        self.sequence_length = args.seqlen\n","        self.target_length = args.tarlen\n","        self.data_root = args.path + args.dataset\n","\n","        self.user_interactions = []\n","        self.user_ratings = []\n","        self.train = Instances(name='Train Instances')\n","        self.test = Instances(name='Test Instances')\n","        self.num_users = 0\n","        self.num_items = 0\n","        self.num_sequences = 0\n","\n","    def process_dataset(self):\n","        print('Root', self.data_root)\n","        self._read_file(self.data_root + '/ml-100k')\n","        self.user_interactions = np.array(self.user_interactions, dtype=object)\n","        self.user_ratings = np.array(self.user_ratings, dtype=object)\n","\n","        self.num_users = self.user_interactions.shape[0]\n","        self.num_items = int(np.max(np.concatenate(self.user_interactions[:])))\n","\n","        print('num_users = ', self.num_users)\n","        print('num_items = ', self.num_items)\n","\n","    def _read_file(self, file_path):\n","        with open(file_path, 'r') as fin:\n","            for line in fin:\n","                item_ratings = line.strip().split()[1:]\n","                item_ratings_np = np.array(item_ratings).astype(np.int64).reshape(-1, 2)\n","                \n","                ### users must have rated at least 15 items\n","                # if item_ratings_np.shape[0] >= 15:\n","                self.user_interactions.append(item_ratings_np[:, 0])\n","                self.user_ratings.append(item_ratings_np[:, 1])\n","\n","    def create_instances(self):\n","        self._create_test_instances()\n","        self._create_train_instances()\n","\n","    def _create_test_instances(self):\n","\n","        ### Creating last item as prediction item\n","        ### Test targets are compaible with sigmoid output and sparse softmax out\n","        for user_id, interaction in enumerate(zip(self.user_interactions, self.user_ratings)):\n","            # interaction[0] --> user sequenes\n","            # interaction[1] --> user ratings\n","            sequence_interation = interaction[0]\n","            sequnece_rating = interaction[1]\n","\n","            if len(sequence_interation) < 3:\n","                continue\n","            ### Users\n","            self.test.users.append(user_id)\n","\n","            ### Targets\n","            self.test.targets.append(sequence_interation[-self.target_length:] - 1)\n","\n","            ### Sequences\n","            sequence_interation = sequence_interation[:-self.target_length]  # Most important line\n","            sequnece_rating = sequnece_rating[:-self.target_length]  # Most important line\n","\n","            if len(sequence_interation) < self.sequence_length:\n","                num_paddings = self.sequence_length - len(sequence_interation)\n","                sequence_interation = np.pad(sequence_interation, (num_paddings, 0), 'constant')\n","                sequnece_rating = np.pad(sequnece_rating, (num_paddings, 0), 'constant')\n","            else:\n","                sequence_interation = sequence_interation[-self.sequence_length:]\n","                sequnece_rating = sequnece_rating[-self.sequence_length:]\n","\n","            self.test.sequences.append(sequence_interation)\n","            self.test.ratings.append(sequnece_rating)\n","\n","        self.test.targets = np.array(self.test.targets).reshape(-1, self.target_length)\n","        ### users\n","        self.test.users = np.array(self.test.users).reshape(-1, 1)\n","        self.test.sequences = np.array(self.test.sequences)\n","        self.test.ratings = np.array(self.test.ratings)\n","\n","        self.test.pprint()\n","\n","    def _create_train_instances(self):\n","        max_sequence_length = self.sequence_length + self.target_length\n","\n","        self.user_sequence_indexes = [list() for i in range(self.num_users)]\n","\n","        sequence_index = 0\n","        for user_id, interaction in enumerate(zip(self.user_interactions, self.user_ratings)):\n","            # interaction[0] --> user sequenes\n","            # interaction[1] --> user ratings\n","            sequence_interation = interaction[0]\n","            sequnece_rating = interaction[1]\n","\n","            if len(sequence_interation) < 3:\n","                continue\n","            sequence_interation = sequence_interation[:-self.target_length]  # Most important line\n","            sequnece_rating = sequnece_rating[:-self.target_length]  # Most important line\n","\n","            if len(sequence_interation) < max_sequence_length:\n","                num_paddings = max_sequence_length - len(sequence_interation)\n","                sequence_interation = np.pad(sequence_interation, (num_paddings, 0), 'constant')\n","                sequnece_rating = np.pad(sequnece_rating, (num_paddings, 0), 'constant')\n","\n","                self._add_sequence(\n","                    seq=sequence_interation[:self.sequence_length], \n","                    usr=user_id, \n","                    rating=sequnece_rating[:self.sequence_length], \n","                    target=sequence_interation[-self.target_length:], \n","                    sequence_index=sequence_index\n","                )\n","                sequence_index += 1\n","\n","            else:\n","                for ind in range(len(sequence_interation), max_sequence_length - 1, -1):\n","                    temp_sequence = sequence_interation[ind - max_sequence_length: ind]\n","                    temp_rating = sequnece_rating[ind - max_sequence_length: ind]\n","                    self._add_sequence(\n","                        seq=temp_sequence[:self.sequence_length], \n","                        usr=user_id, \n","                        rating=temp_rating[:self.sequence_length], \n","                        target=temp_sequence[-self.target_length:], \n","                        sequence_index=sequence_index\n","                    )\n","                    sequence_index += 1\n","\n","        self.train.sequences = np.array(self.train.sequences)\n","        self.train.ratings = np.array(self.train.ratings)\n","        self.train.users = np.array(self.train.users).reshape(-1, 1)\n","        self.train.targets = np.array(self.train.targets)\n","        self.train.pprint()\n","\n","        for user_id in range(self.num_users):\n","            self.user_sequence_indexes[user_id] = np.array(self.user_sequence_indexes[user_id])\n","        self.user_sequence_indexes = np.array(self.user_sequence_indexes, dtype=object)\n","\n","        self.num_sequences = sequence_index\n","\n","    def _add_sequence(self, seq, usr, rating, target, sequence_index):\n","        self.train.sequences.append(seq)\n","        self.train.ratings.append(rating)\n","        self.train.users.append(usr)\n","        if target == 0:\n","            self.train.targets.append(target)\n","        else:\n","            self.train.targets.append(target - 1)\n","\n","        self.user_sequence_indexes[usr].append(sequence_index)\n","        "]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1683141802856,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"GvVaRppTzUBo"},"outputs":[],"source":["class InstanceSpliter:\n","\n","    def __init__(self, data, k_fold = 5):\n","        self.data = data\n","        self.k_fold = k_fold\n","\n","    def generate_folds(self):\n","        n_user_fold = self.data.num_users // self.k_fold\n","        user_ids = np.arange(self.data.num_users)\n","        np.random.shuffle(user_ids)\n","\n","        ### Find folds for users\n","        self.user_fold_indexes = []\n","        for fold in range(self.k_fold):\n","            self.user_fold_indexes.append(user_ids[fold*n_user_fold : (fold+1)*n_user_fold])\n","        self.user_fold_indexes = np.array(self.user_fold_indexes)\n","\n","    def get_sequence_indexes(self, fold_indexes):\n","        # print(fold_indexes)\n","        return np.concatenate(self.data.user_sequence_indexes[fold_indexes])\n","\n","    def get_sequence(self, sequence_indexes, isTest=False):\n","        _instances = Instances()\n","        if isTest:\n","            _split_instances = self.data.test\n","        else:\n","            _split_instances = self.data.train\n","\n","        print(type(sequence_indexes))\n","        _instances.users = _split_instances.users[sequence_indexes]\n","        _instances.sequences = _split_instances.sequences[sequence_indexes]\n","        _instances.ratings = _split_instances.ratings[sequence_indexes]\n","        _instances.targets = _split_instances.targets[sequence_indexes]\n","\n","        return _instances\n","\n","    def split_data(self, fold_id=0):\n","        if fold_id >= self.k_fold:\n","            raise Exception('Fold Id must be less than the k_fold')\n","\n","        test_user_indexes = self.user_fold_indexes[fold_id]\n","        train_user_indexes = np.array(list(set(np.arange(self.data.num_users)) - set(self.user_fold_indexes[fold_id])))\n","\n","        return self.create_split(train_user_indexes, test_user_indexes)\n","        \n","    def create_split(self, train_user_indexes, test_user_indexes):    \n","        train_sequence_indexes = self.get_sequence_indexes(train_user_indexes)\n","        validation_sequence_indexes = self.get_sequence_indexes(test_user_indexes)\n","\n","        train_set = self.get_sequence(train_sequence_indexes)\n","        validation_set = self.get_sequence(validation_sequence_indexes)\n","        test_set = self.get_sequence(test_user_indexes, isTest=True)\n","\n","        # if len(set(train_set.users.squeeze()).intersection(set(test_set.users.squeeze())))==0:\n","        # if len(set(train_user_indexes).intersection(set(test_user_indexes))) == 0:\n","        #     print('Well Done')\n","        # else:\n","        #     print('Error Splitting')\n","        print(train_set.users.shape, validation_set.users.shape, np.unique(train_set.users.squeeze()).shape, validation_set.users.shape)\n","\n","        train_set.shuffle()\n","        validation_set.shuffle()\n","    \n","        return train_set, validation_set, test_set\n","\n","\n","def init(args, k_fold=5):\n","    set_seed(args.setseed)\n","\n","    # load dataset\n","    instances = Interactions(args)\n","    instances.process_dataset()\n","    instances.create_instances()\n","\n","    # get_target_samples(instances, num_negative_samples=1)\n","\n","    instance_spliter = InstanceSpliter(data=instances, k_fold=k_fold)\n","    instance_spliter.generate_folds()\n","\n","    return instances, instance_spliter"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2903,"status":"ok","timestamp":1683141805750,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"pzQT43PgOQgn","outputId":"563bdbdf-d0e1-4795-def0-2f0f163f1733"},"outputs":[{"name":"stdout","output_type":"stream","text":["Root ml-100k\n","num_users =  943\n","num_items =  1681\n","Data Instances Shape: Test Instances\n","Sequences: (943, 100) Users: (943, 1) Targets: (943, 1) Ratings: (943, 100)\n","Data Instances Shape: Train Instances\n","Sequences: (38346, 100) Users: (38346, 1) Targets: (38346, 1) Ratings: (38346, 100)\n","<class 'numpy.ndarray'>\n","<class 'numpy.ndarray'>\n","<class 'numpy.ndarray'>\n","(31922, 1) (6424, 1) (755,) (6424, 1)\n"]}],"source":["args.seqlen = 100\n","args.embed_dims=64\n","args.residual_channels=64\n","\n","data, spliter = init(args)\n","train, validation, test = spliter.split_data(fold_id=0)"]},{"cell_type":"markdown","metadata":{"id":"sMbaNpTqGhVy"},"source":["### Uncertainty Calculations"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683141805751,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"PvrgfzWwkaqn"},"outputs":[],"source":["def CustomSparseCategoricalCrossentropyLoss(T):\n","    def Custom_Loss(y_true, y_pred):\n","        varience = y_pred[:, -1]\n","        before_softmax = y_pred[:, :-1]\n","\n","        std = tf.sqrt(varience)\n","        dist = tfd.Normal(loc=tf.zeros_like(std), scale=std)\n","\n","        std_samples = tf.transpose(dist.sample(y_pred.shape[1]))\n","        std_samples = tf.reshape(std_samples, shape=(tf.shape(y_pred)[0], y_pred.shape[1]))\n","        monte_carlo_results = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred + std_samples, from_logits=True)\n","        \n","        variance_loss = tf.reduce_mean(monte_carlo_results, axis=0)\n","\n","        return tf.math.log(variance_loss)\n","    return Custom_Loss\n","\n","def CustomSparseTopKCategoricalAccuracy(y_true, y_pred):\n","\n","    varience = tf.reshape(y_pred[:,-1], (-1,1))\n","    y_pred = y_pred[:,:-1]\n","    y_pred = tf.nn.softmax(y_pred)\n","\n","    m = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=20)\n","    m.update_state(y_true, y_pred)\n","    return m.result()\n","\n","    # return tf.math.reduce_mean(tf.cast(tf.equal(tf.argmax(y_true, axis=-1), tf.argmax(y_pred, axis=-1)), tf.float64))\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683141805751,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"K0O-zLdZG_Ir"},"outputs":[],"source":["def test_model(nnRecModel, train, val, test):\n","    max_epochs = 10\n","    verbose = 1\n","    batch_size = 512\n","    for iteration in range(max_epochs):\n","        history = nnRecModel.fit(train.sequences, train.targets,\n","            verbose=verbose, \n","            batch_size=batch_size,\n","            # validation_data=(val.sequences, val.targets),\n","            # validation_batch_size=batch_size,\n","            callbacks=tf.keras.callbacks.TerminateOnNaN(),\n","        )\n","        y_pred = nnRecModel.predict(test.sequences, batch_size=batch_size)\n","        print('Test Accuracy: ', CustomSparseTopKCategoricalAccuracy(test.targets, y_pred))"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683141805752,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"Z6lB7N6Yt_F6"},"outputs":[],"source":["class nnRecSys:\n","    def __init__(self, args, data):\n","        self.T = args.T\n","        self.data = data\n","        self.saved_dir = 'results/'\n","        self.sequence_length = args.seqlen\n","        self.num_users = data.num_users\n","        self.num_items = data.num_items  # Consider padding 0 a prediction\n","\n","    def compile_model(self, inputs, outputs):\n","        model = tf.keras.Model(\n","            inputs=inputs,\n","            outputs=outputs,\n","        )\n","        ### model compile\n","        model.compile(\n","            optimizer=tf.keras.optimizers.Adam(learning_rate=2e-3, beta_1=0.9, beta_2=0.999, clipvalue=1.0),\n","            # optimizer=tf.keras.optimizers.Adam(\n","            #     learning_rate=tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3, decay_steps=200, decay_rate=0.80, staircase=True, name=None)\n","            #     # learning_rate=tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=1e-3, decay_steps=250, alpha=0.0, name=None)\n","            #     # learning_rate=tf.keras.optimizers.schedules.InverseTimeDecay(initial_learning_rate=1e-4, decay_steps=400, decay_rate=0.75, name=None)\n","\n","            # ),\n","            # loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","            loss=CustomSparseCategoricalCrossentropyLoss(self.T),\n","            metrics=[CustomSparseTopKCategoricalAccuracy],\n","        )\n","\n","        return model\n","\n","args.T = 1\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3166,"status":"ok","timestamp":1683141808913,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"ChioSTAzS0ov","outputId":"cb2f0ddb-67c2-47b9-f614-c948e901df3d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 1681)              169781    \n","                                                                 \n"," distribution_lambda (Distri  ((1681, None),           0         \n"," butionLambda)                (1681, None))                      \n","                                                                 \n","=================================================================\n","Total params: 169,781\n","Trainable params: 169,781\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["tfk = tf.keras\n","tfkl = tf.keras.layers\n","tfd = tfp.distributions\n","tfpl = tfp.layers\n","\n","model = tfk.Sequential([\n","  tfkl.Dense(1681, input_dim=100),\n","  tfpl.DistributionLambda(\n","    make_distribution_fn=lambda t: tfd.Normal(loc=t[..., 0], scale=tf.exp(t[..., 1])),\n","    convert_to_tensor_fn=lambda s: s.sample(1681))\n","])\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"Z-TDePCl7jEe"},"source":["#### NextItNet"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":384,"status":"ok","timestamp":1683145426092,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"W9em3MFWlTFY","outputId":"a6ae81ab-3305-4b7e-9860-00e50dfc0777"},"outputs":[{"name":"stdout","output_type":"stream","text":["(None, 1)\n","Sampled Shape from distribution: (None, 1681)\n"]},{"data":{"image/svg+xml":["<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"515pt\" height=\"1512pt\" viewBox=\"0.00 0.00 386.00 1134.00\">\n","<g id=\"graph0\" class=\"graph\" transform=\"scale(1.33333 1.33333) rotate(0) translate(4 1130)\">\n","<title>G</title>\n","<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-1130 382,-1130 382,4 -4,4\"/>\n","<!-- 2310089918112 -->\n","<g id=\"node1\" class=\"node\">\n","<title>2310089918112</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"76.5,-1079.5 76.5,-1125.5 301.5,-1125.5 301.5,-1079.5 76.5,-1079.5\"/>\n","<text text-anchor=\"middle\" x=\"115\" y=\"-1110.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">seq_input</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"76.5,-1102.5 153.5,-1102.5\"/>\n","<text text-anchor=\"middle\" x=\"115\" y=\"-1087.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">InputLayer</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"153.5,-1079.5 153.5,-1125.5\"/>\n","<text text-anchor=\"middle\" x=\"181.5\" y=\"-1110.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"153.5,-1102.5 209.5,-1102.5\"/>\n","<text text-anchor=\"middle\" x=\"181.5\" y=\"-1087.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"209.5,-1079.5 209.5,-1125.5\"/>\n","<text text-anchor=\"middle\" x=\"255.5\" y=\"-1110.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[(None, 100)]</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"209.5,-1102.5 301.5,-1102.5\"/>\n","<text text-anchor=\"middle\" x=\"255.5\" y=\"-1087.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[(None, 100)]</text>\n","</g>\n","<!-- 2310091264448 -->\n","<g id=\"node2\" class=\"node\">\n","<title>2310091264448</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"56.5,-996.5 56.5,-1042.5 321.5,-1042.5 321.5,-996.5 56.5,-996.5\"/>\n","<text text-anchor=\"middle\" x=\"109\" y=\"-1027.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">seq_embedding</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"56.5,-1019.5 161.5,-1019.5\"/>\n","<text text-anchor=\"middle\" x=\"109\" y=\"-1004.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Embedding</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"161.5,-996.5 161.5,-1042.5\"/>\n","<text text-anchor=\"middle\" x=\"189.5\" y=\"-1027.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"161.5,-1019.5 217.5,-1019.5\"/>\n","<text text-anchor=\"middle\" x=\"189.5\" y=\"-1004.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"217.5,-996.5 217.5,-1042.5\"/>\n","<text text-anchor=\"middle\" x=\"269.5\" y=\"-1027.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 100)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"217.5,-1019.5 321.5,-1019.5\"/>\n","<text text-anchor=\"middle\" x=\"269.5\" y=\"-1004.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","</g>\n","<!-- 2310089918112&#45;&gt;2310091264448 -->\n","<g id=\"edge1\" class=\"edge\">\n","<title>2310089918112-&gt;2310091264448</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M189,-1079.79C189,-1071.62 189,-1062.14 189,-1053.19\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-1053.27 189,-1043.27 185.5,-1053.27 192.5,-1053.27\"/>\n","</g>\n","<!-- 2310089925392 -->\n","<g id=\"node3\" class=\"node\">\n","<title>2310089925392</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"72.5,-913.5 72.5,-959.5 305.5,-959.5 305.5,-913.5 72.5,-913.5\"/>\n","<text text-anchor=\"middle\" x=\"109\" y=\"-944.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">conv1d_6</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"72.5,-936.5 145.5,-936.5\"/>\n","<text text-anchor=\"middle\" x=\"109\" y=\"-921.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Conv1D</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"145.5,-913.5 145.5,-959.5\"/>\n","<text text-anchor=\"middle\" x=\"173.5\" y=\"-944.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"145.5,-936.5 201.5,-936.5\"/>\n","<text text-anchor=\"middle\" x=\"173.5\" y=\"-921.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"201.5,-913.5 201.5,-959.5\"/>\n","<text text-anchor=\"middle\" x=\"253.5\" y=\"-944.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"201.5,-936.5 305.5,-936.5\"/>\n","<text text-anchor=\"middle\" x=\"253.5\" y=\"-921.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 98, 64)</text>\n","</g>\n","<!-- 2310091264448&#45;&gt;2310089925392 -->\n","<g id=\"edge2\" class=\"edge\">\n","<title>2310091264448-&gt;2310089925392</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M189,-996.79C189,-988.62 189,-979.14 189,-970.19\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-970.27 189,-960.27 185.5,-970.27 192.5,-970.27\"/>\n","</g>\n","<!-- 2310089894688 -->\n","<g id=\"node4\" class=\"node\">\n","<title>2310089894688</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"70.5,-830.5 70.5,-876.5 307.5,-876.5 307.5,-830.5 70.5,-830.5\"/>\n","<text text-anchor=\"middle\" x=\"112\" y=\"-861.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dropout_10</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"70.5,-853.5 153.5,-853.5\"/>\n","<text text-anchor=\"middle\" x=\"112\" y=\"-838.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dropout</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"153.5,-830.5 153.5,-876.5\"/>\n","<text text-anchor=\"middle\" x=\"181.5\" y=\"-861.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"153.5,-853.5 209.5,-853.5\"/>\n","<text text-anchor=\"middle\" x=\"181.5\" y=\"-838.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"209.5,-830.5 209.5,-876.5\"/>\n","<text text-anchor=\"middle\" x=\"258.5\" y=\"-861.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 98, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"209.5,-853.5 307.5,-853.5\"/>\n","<text text-anchor=\"middle\" x=\"258.5\" y=\"-838.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 98, 64)</text>\n","</g>\n","<!-- 2310089925392&#45;&gt;2310089894688 -->\n","<g id=\"edge3\" class=\"edge\">\n","<title>2310089925392-&gt;2310089894688</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M189,-913.79C189,-905.62 189,-896.14 189,-887.19\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-887.27 189,-877.27 185.5,-887.27 192.5,-887.27\"/>\n","</g>\n","<!-- 2310089924960 -->\n","<g id=\"node5\" class=\"node\">\n","<title>2310089924960</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"75.5,-747.5 75.5,-793.5 302.5,-793.5 302.5,-747.5 75.5,-747.5\"/>\n","<text text-anchor=\"middle\" x=\"112\" y=\"-778.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">conv1d_7</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"75.5,-770.5 148.5,-770.5\"/>\n","<text text-anchor=\"middle\" x=\"112\" y=\"-755.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Conv1D</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"148.5,-747.5 148.5,-793.5\"/>\n","<text text-anchor=\"middle\" x=\"176.5\" y=\"-778.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"148.5,-770.5 204.5,-770.5\"/>\n","<text text-anchor=\"middle\" x=\"176.5\" y=\"-755.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"204.5,-747.5 204.5,-793.5\"/>\n","<text text-anchor=\"middle\" x=\"253.5\" y=\"-778.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 98, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"204.5,-770.5 302.5,-770.5\"/>\n","<text text-anchor=\"middle\" x=\"253.5\" y=\"-755.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 94, 64)</text>\n","</g>\n","<!-- 2310089894688&#45;&gt;2310089924960 -->\n","<g id=\"edge4\" class=\"edge\">\n","<title>2310089894688-&gt;2310089924960</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M189,-830.79C189,-822.62 189,-813.14 189,-804.19\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-804.27 189,-794.27 185.5,-804.27 192.5,-804.27\"/>\n","</g>\n","<!-- 2310090360192 -->\n","<g id=\"node6\" class=\"node\">\n","<title>2310090360192</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"70.5,-664.5 70.5,-710.5 307.5,-710.5 307.5,-664.5 70.5,-664.5\"/>\n","<text text-anchor=\"middle\" x=\"112\" y=\"-695.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dropout_11</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"70.5,-687.5 153.5,-687.5\"/>\n","<text text-anchor=\"middle\" x=\"112\" y=\"-672.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dropout</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"153.5,-664.5 153.5,-710.5\"/>\n","<text text-anchor=\"middle\" x=\"181.5\" y=\"-695.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"153.5,-687.5 209.5,-687.5\"/>\n","<text text-anchor=\"middle\" x=\"181.5\" y=\"-672.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"209.5,-664.5 209.5,-710.5\"/>\n","<text text-anchor=\"middle\" x=\"258.5\" y=\"-695.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 94, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"209.5,-687.5 307.5,-687.5\"/>\n","<text text-anchor=\"middle\" x=\"258.5\" y=\"-672.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 94, 64)</text>\n","</g>\n","<!-- 2310089924960&#45;&gt;2310090360192 -->\n","<g id=\"edge5\" class=\"edge\">\n","<title>2310089924960-&gt;2310090360192</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M189,-747.79C189,-739.62 189,-730.14 189,-721.19\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-721.27 189,-711.27 185.5,-721.27 192.5,-721.27\"/>\n","</g>\n","<!-- 2310089896048 -->\n","<g id=\"node7\" class=\"node\">\n","<title>2310089896048</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"75.5,-581.5 75.5,-627.5 302.5,-627.5 302.5,-581.5 75.5,-581.5\"/>\n","<text text-anchor=\"middle\" x=\"112\" y=\"-612.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">conv1d_8</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"75.5,-604.5 148.5,-604.5\"/>\n","<text text-anchor=\"middle\" x=\"112\" y=\"-589.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Conv1D</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"148.5,-581.5 148.5,-627.5\"/>\n","<text text-anchor=\"middle\" x=\"176.5\" y=\"-612.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"148.5,-604.5 204.5,-604.5\"/>\n","<text text-anchor=\"middle\" x=\"176.5\" y=\"-589.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"204.5,-581.5 204.5,-627.5\"/>\n","<text text-anchor=\"middle\" x=\"253.5\" y=\"-612.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 94, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"204.5,-604.5 302.5,-604.5\"/>\n","<text text-anchor=\"middle\" x=\"253.5\" y=\"-589.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 86, 64)</text>\n","</g>\n","<!-- 2310090360192&#45;&gt;2310089896048 -->\n","<g id=\"edge6\" class=\"edge\">\n","<title>2310090360192-&gt;2310089896048</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M189,-664.79C189,-656.62 189,-647.14 189,-638.19\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-638.27 189,-628.27 185.5,-638.27 192.5,-638.27\"/>\n","</g>\n","<!-- 2310090442352 -->\n","<g id=\"node8\" class=\"node\">\n","<title>2310090442352</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"70.5,-498.5 70.5,-544.5 307.5,-544.5 307.5,-498.5 70.5,-498.5\"/>\n","<text text-anchor=\"middle\" x=\"112\" y=\"-529.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dropout_12</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"70.5,-521.5 153.5,-521.5\"/>\n","<text text-anchor=\"middle\" x=\"112\" y=\"-506.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dropout</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"153.5,-498.5 153.5,-544.5\"/>\n","<text text-anchor=\"middle\" x=\"181.5\" y=\"-529.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"153.5,-521.5 209.5,-521.5\"/>\n","<text text-anchor=\"middle\" x=\"181.5\" y=\"-506.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"209.5,-498.5 209.5,-544.5\"/>\n","<text text-anchor=\"middle\" x=\"258.5\" y=\"-529.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 86, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"209.5,-521.5 307.5,-521.5\"/>\n","<text text-anchor=\"middle\" x=\"258.5\" y=\"-506.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 86, 64)</text>\n","</g>\n","<!-- 2310089896048&#45;&gt;2310090442352 -->\n","<g id=\"edge7\" class=\"edge\">\n","<title>2310089896048-&gt;2310090442352</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M189,-581.79C189,-573.62 189,-564.14 189,-555.19\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-555.27 189,-545.27 185.5,-555.27 192.5,-555.27\"/>\n","</g>\n","<!-- 2310090540512 -->\n","<g id=\"node9\" class=\"node\">\n","<title>2310090540512</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"27,-415.5 27,-461.5 351,-461.5 351,-415.5 27,-415.5\"/>\n","<text text-anchor=\"middle\" x=\"112\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">tf.__operators__.getitem_2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"27,-438.5 197,-438.5\"/>\n","<text text-anchor=\"middle\" x=\"112\" y=\"-423.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SlicingOpLambda</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"197,-415.5 197,-461.5\"/>\n","<text text-anchor=\"middle\" x=\"225\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"197,-438.5 253,-438.5\"/>\n","<text text-anchor=\"middle\" x=\"225\" y=\"-423.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"253,-415.5 253,-461.5\"/>\n","<text text-anchor=\"middle\" x=\"302\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 86, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"253,-438.5 351,-438.5\"/>\n","<text text-anchor=\"middle\" x=\"302\" y=\"-423.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n","</g>\n","<!-- 2310090442352&#45;&gt;2310090540512 -->\n","<g id=\"edge8\" class=\"edge\">\n","<title>2310090442352-&gt;2310090540512</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M189,-498.79C189,-490.62 189,-481.14 189,-472.19\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-472.27 189,-462.27 185.5,-472.27 192.5,-472.27\"/>\n","</g>\n","<!-- 2310090540608 -->\n","<g id=\"node10\" class=\"node\">\n","<title>2310090540608</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"73.5,-332.5 73.5,-378.5 304.5,-378.5 304.5,-332.5 73.5,-332.5\"/>\n","<text text-anchor=\"middle\" x=\"122.5\" y=\"-363.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">tf.reshape_2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"73.5,-355.5 171.5,-355.5\"/>\n","<text text-anchor=\"middle\" x=\"122.5\" y=\"-340.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">TFOpLambda</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"171.5,-332.5 171.5,-378.5\"/>\n","<text text-anchor=\"middle\" x=\"199.5\" y=\"-363.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"171.5,-355.5 227.5,-355.5\"/>\n","<text text-anchor=\"middle\" x=\"199.5\" y=\"-340.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"227.5,-332.5 227.5,-378.5\"/>\n","<text text-anchor=\"middle\" x=\"266\" y=\"-363.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"227.5,-355.5 304.5,-355.5\"/>\n","<text text-anchor=\"middle\" x=\"266\" y=\"-340.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n","</g>\n","<!-- 2310090540512&#45;&gt;2310090540608 -->\n","<g id=\"edge9\" class=\"edge\">\n","<title>2310090540512-&gt;2310090540608</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M189,-415.79C189,-407.62 189,-398.14 189,-389.19\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-389.27 189,-379.27 185.5,-389.27 192.5,-389.27\"/>\n","</g>\n","<!-- 2310091246416 -->\n","<g id=\"node11\" class=\"node\">\n","<title>2310091246416</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"81,-249.5 81,-295.5 297,-295.5 297,-249.5 81,-249.5\"/>\n","<text text-anchor=\"middle\" x=\"122.5\" y=\"-280.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dropout_13</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"81,-272.5 164,-272.5\"/>\n","<text text-anchor=\"middle\" x=\"122.5\" y=\"-257.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dropout</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"164,-249.5 164,-295.5\"/>\n","<text text-anchor=\"middle\" x=\"192\" y=\"-280.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"164,-272.5 220,-272.5\"/>\n","<text text-anchor=\"middle\" x=\"192\" y=\"-257.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"220,-249.5 220,-295.5\"/>\n","<text text-anchor=\"middle\" x=\"258.5\" y=\"-280.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"220,-272.5 297,-272.5\"/>\n","<text text-anchor=\"middle\" x=\"258.5\" y=\"-257.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n","</g>\n","<!-- 2310090540608&#45;&gt;2310091246416 -->\n","<g id=\"edge10\" class=\"edge\">\n","<title>2310090540608-&gt;2310091246416</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M189,-332.79C189,-324.62 189,-315.14 189,-306.19\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-306.27 189,-296.27 185.5,-306.27 192.5,-306.27\"/>\n","</g>\n","<!-- 2310090483264 -->\n","<g id=\"node12\" class=\"node\">\n","<title>2310090483264</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"84.5,-166.5 84.5,-212.5 293.5,-212.5 293.5,-166.5 84.5,-166.5\"/>\n","<text text-anchor=\"middle\" x=\"116\" y=\"-197.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dense_3</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"84.5,-189.5 147.5,-189.5\"/>\n","<text text-anchor=\"middle\" x=\"116\" y=\"-174.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dense</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"147.5,-166.5 147.5,-212.5\"/>\n","<text text-anchor=\"middle\" x=\"175.5\" y=\"-197.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"147.5,-189.5 203.5,-189.5\"/>\n","<text text-anchor=\"middle\" x=\"175.5\" y=\"-174.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"203.5,-166.5 203.5,-212.5\"/>\n","<text text-anchor=\"middle\" x=\"248.5\" y=\"-197.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"203.5,-189.5 293.5,-189.5\"/>\n","<text text-anchor=\"middle\" x=\"248.5\" y=\"-174.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 1682)</text>\n","</g>\n","<!-- 2310091246416&#45;&gt;2310090483264 -->\n","<g id=\"edge11\" class=\"edge\">\n","<title>2310091246416-&gt;2310090483264</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M189,-249.79C189,-241.62 189,-232.14 189,-223.19\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-223.27 189,-213.27 185.5,-223.27 192.5,-223.27\"/>\n","</g>\n","<!-- 2310090484704 -->\n","<g id=\"node13\" class=\"node\">\n","<title>2310090484704</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"74.5,-83.5 74.5,-129.5 303.5,-129.5 303.5,-83.5 74.5,-83.5\"/>\n","<text text-anchor=\"middle\" x=\"116\" y=\"-114.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dropout_14</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"74.5,-106.5 157.5,-106.5\"/>\n","<text text-anchor=\"middle\" x=\"116\" y=\"-91.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dropout</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"157.5,-83.5 157.5,-129.5\"/>\n","<text text-anchor=\"middle\" x=\"185.5\" y=\"-114.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"157.5,-106.5 213.5,-106.5\"/>\n","<text text-anchor=\"middle\" x=\"185.5\" y=\"-91.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"213.5,-83.5 213.5,-129.5\"/>\n","<text text-anchor=\"middle\" x=\"258.5\" y=\"-114.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 1682)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"213.5,-106.5 303.5,-106.5\"/>\n","<text text-anchor=\"middle\" x=\"258.5\" y=\"-91.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 1682)</text>\n","</g>\n","<!-- 2310090483264&#45;&gt;2310090484704 -->\n","<g id=\"edge12\" class=\"edge\">\n","<title>2310090483264-&gt;2310090484704</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M189,-166.79C189,-158.62 189,-149.14 189,-140.19\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-140.27 189,-130.27 185.5,-140.27 192.5,-140.27\"/>\n","</g>\n","<!-- 2310090511984 -->\n","<g id=\"node14\" class=\"node\">\n","<title>2310090511984</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-46.5 378,-46.5 378,-0.5 0,-0.5\"/>\n","<text text-anchor=\"middle\" x=\"71\" y=\"-31.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">distribution_lambda_3</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"0,-23.5 142,-23.5\"/>\n","<text text-anchor=\"middle\" x=\"71\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">DistributionLambda</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"142,-0.5 142,-46.5\"/>\n","<text text-anchor=\"middle\" x=\"170\" y=\"-31.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"142,-23.5 198,-23.5\"/>\n","<text text-anchor=\"middle\" x=\"170\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"198,-0.5 198,-46.5\"/>\n","<text text-anchor=\"middle\" x=\"288\" y=\"-31.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 1682)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"198,-23.5 378,-23.5\"/>\n","<text text-anchor=\"middle\" x=\"288\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">((None, 1681), (None, 1681))</text>\n","</g>\n","<!-- 2310090484704&#45;&gt;2310090511984 -->\n","<g id=\"edge13\" class=\"edge\">\n","<title>2310090484704-&gt;2310090511984</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M189,-83.79C189,-75.62 189,-66.14 189,-57.19\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-57.27 189,-47.27 185.5,-57.27 192.5,-57.27\"/>\n","</g>\n","</g>\n","</svg>"],"text/plain":["<IPython.core.display.SVG object>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["def CustomLoss():\n","    def Custom_Loss(y_true, y_pred):\n","        # print(y_pred.shape)\n","        # print(y_true.shape)\n","        return tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n","    return Custom_Loss\n","\n","lmbda = 0.125\n","\n","class NextItNet_Dropout(nnRecSys):\n","    def __init__(self, args, data):        \n","        super(NextItNet_Dropout, self).__init__(args, data)\n","        self.saved_dir = self.saved_dir + 'NextItNet_Dropout/' + args.dataset + '/'\n","        self.embed_dim = args.embed_dims                    # 256\n","        self.residual_channels = args.residual_channels     # 256\n","        self.dilations = args.dilations                     # [1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4]\n","        self.kernel_size = args.kernel_size            # 3\n","\n","    def get_model(self, drop_prob=0.25, isDropoutTraining=True):\n","        # embed_dim = 64          # 256\n","        # embed_size = 64         # 256\n","        # dilations = [1, 2, 4]   # [1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4]\n","        # residual_channels = 32  # 256\n","        # kernel_size = 3         # 3\n","\n","        user_input = tf.keras.layers.Input(shape=(1,), name='user_input')\n","        item_input = tf.keras.layers.Input(shape=(1,), name='item_input')\n","\n","        seq_input = tf.keras.layers.Input(shape=(self.sequence_length,), name='seq_input')\n","\n","\n","        user_embed = tf.keras.layers.Embedding(self.num_users, self.embed_dim, embeddings_regularizer=tf.keras.regularizers.L2(0))(user_input) #(N, k)\n","        item_embed = tf.keras.layers.Embedding(self.num_items, self.embed_dim, embeddings_regularizer=tf.keras.regularizers.L2(0))(item_input) #(M, k)\n","\n","        \n","\n","\n","        # (batch_size, sequence_length, embed_dim) --> (None, 100, 64)\n","        seq_embedding = tf.keras.layers.Embedding(\n","            input_dim = self.num_items, \n","            output_dim = self.embed_dim,\n","            name='seq_embedding',\n","            embeddings_initializer='uniform',       #embeding.weight.data.uniform_(-stdv, stdv) # important initializer, stdv = np.sqrt(1. / self.item_size)\n","            embeddings_regularizer=tf.keras.regularizers.L2(0)\n","        )(seq_input) #(batch_size, seq_len, embed_dim) = (None, 100, 64)\n","        # conv_layer = tf.keras.layers.Dropout(drop_prob)(seq_embedding, training=isDropoutTraining)\n","        conv_layer=seq_embedding\n","\n","        # conv_layer = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(conv_layer) #(batch_size, seq_len, embed_dim, 1) (None, 100, 64, 1)\n","\n","\n","        for dilation in self.dilations: #[1, 2, 4]\n","\n","            conv_layer = tf.keras.layers.Conv1D(\n","                    self.residual_channels, \n","                    kernel_size=self.kernel_size, \n","                    dilation_rate=dilation, \n","                    padding='valid', \n","                    activation='tanh',\n","                )(conv_layer) # (batch_size, seq_len, embed_dim, residual_channels) = (None, 100, 98, 32), (None, 100, 94, 32), (None, 100, 86, 32)\n","            conv_layer = tf.keras.layers.Dropout(drop_prob)(conv_layer, training=isDropoutTraining)\n","\n","        flatten_layer = tf.reshape(conv_layer[:, -1,], (-1, self.residual_channels)) # (batch_size, embed_dim) = (None, 32)\n","        flatten_layer = tf.keras.layers.Dropout(drop_prob)(flatten_layer, training=isDropoutTraining)\n","        \n","        variance_layer = tf.keras.layers.Dense(1, activation='softplus',name='variance')(flatten_layer)\n","        print(variance_layer.shape)\n","\n","        # std = tf.sqrt(variance_layer)\n","        # print(std.shape)\n","        # dist = tfd.Normal(loc=tf.zeros_like(std), scale=std)\n","        # # print(dist.shape)\n","        # std_samples = tf.transpose(dist.sample(self.num_items))\n","        # std_samples = tf.reshape(std_samples, shape=(512, self.num_items))\n","\n","\n","        fully_connected_layer = tf.keras.layers.Dense(self.num_items+1)(flatten_layer) # (batch_size, num_items) = (None, 3417)\n","        fully_connected_layer = tf.keras.layers.Dropout(drop_prob)(fully_connected_layer, training=isDropoutTraining)\n","\n","        # output_layer = tf.keras.layers.concatenate([fully_connected_layer, variance_layer], name='output_layer')\n","\n","        output_layer = tfpl.DistributionLambda(\n","            make_distribution_fn=lambda t: tfd.Normal(loc=t[..., :self.num_items], scale=tf.nn.softplus(t[..., self.num_items:])),\n","            convert_to_tensor_fn=tfd.Distribution.sample\n","            # convert_to_tensor_fn=lambda s: s.sample(100)\n","        )(fully_connected_layer)\n","        # output_layer = output_layer[0]\n","        print('Sampled Shape from distribution:', output_layer.shape)\n","        # logits_variance = tf.keras.layers.concatenate([fully_connected_layer, variance_layer], name='logits_variance')\n","\n","        # final_ratings = (1-lmbda) * fully_connected_layer\n","        #  + lmbda * output_layer\n","        # print(final_ratings.shape)\n","        # output_layer = tf.keras.layers.Dense(self.num_items)(output_layer)\n","\n","        # output_layer = (1-lmbda) * fully_connected_layer[:, :-1] + lmbda * output_layer\n","        model = tf.keras.Model(\n","            inputs=seq_input,\n","            outputs=output_layer\n","            # outputs=fully_connected_layer[:, :self.num_items],\n","        )\n","        model.compile(\n","            optimizer=tf.keras.optimizers.Adam(learning_rate=2e-3, beta_1=0.9, beta_2=0.999, clipvalue=1.0),\n","            # optimizer=tf.keras.optimizers.Adam(\n","            #     learning_rate=tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3, decay_steps=200, decay_rate=0.80, staircase=True, name=None)\n","            #     # learning_rate=tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=1e-3, decay_steps=250, alpha=0.0, name=None)\n","            #     # learning_rate=tf.keras.optimizers.schedules.InverseTimeDecay(initial_learning_rate=1e-4, decay_steps=400, decay_rate=0.75, name=None)\n","\n","            # ),\n","            # loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","            loss=CustomLoss(),\n","            metrics=[CustomSparseTopKCategoricalAccuracy],\n","        )\n","\n","        return model\n","\n","def test_model(nnRecModel, train, val, test):\n","    max_epochs = 10\n","    verbose = 1\n","    batch_size = 512\n","    # for iteration in range(max_epochs):\n","    hist = nnRecModel.fit(train.sequences, train.targets,\n","        verbose=verbose, \n","        batch_size=batch_size,\n","        epochs=max_epochs,\n","        # validation_data=(val.sequences, val.targets),\n","        # validation_batch_size=batch_size,\n","        callbacks=tf.keras.callbacks.TerminateOnNaN(),\n","    )\n","        # y_pred = nnRecModel.predict(test.sequences, batch_size=batch_size)\n","        # print('Test Accuracy: ', CustomSparseTopKCategoricalAccuracy(test.targets, y_pred))\n","    return hist\n","\n","# model = GRU(args, data, T=100).get_model(drop_prob=0.25)\n","model = NextItNet_Dropout(args, data).get_model(drop_prob=0.25)\n","\n","# model = NextItNet_Dropout(data, T=100).get_model(drop_prob=0.25)\n","# model.summary()\n","# hist = test_model(model, train, validation, test)\n","from tensorflow.keras.utils import model_to_dot\n","from IPython.display import SVG\n","SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56510,"status":"ok","timestamp":1683145486126,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"UCFFTWUAkull","outputId":"523065b2-5b31-4b00-fea2-ad1b361941c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Carrt\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]},{"ename":"InvalidArgumentError","evalue":"Exception encountered when calling layer 'seq_embedding' (type Embedding).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[386,20] = 1681 is not in [0, 1681) [Op:ResourceGather]\n\nCall arguments received by layer 'seq_embedding' (type Embedding):\n  • inputs=tf.Tensor(shape=(512, 100), dtype=float32)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hist \u001b[39m=\u001b[39m test_model(model, train, validation, test)\n","Cell \u001b[1;32mIn[13], line 122\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(nnRecModel, train, val, test)\u001b[0m\n\u001b[0;32m    120\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m512\u001b[39m\n\u001b[0;32m    121\u001b[0m \u001b[39m# for iteration in range(max_epochs):\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m hist \u001b[39m=\u001b[39m nnRecModel\u001b[39m.\u001b[39;49mfit(train\u001b[39m.\u001b[39;49msequences, train\u001b[39m.\u001b[39;49mtargets,\n\u001b[0;32m    123\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose, \n\u001b[0;32m    124\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    125\u001b[0m     epochs\u001b[39m=\u001b[39;49mmax_epochs,\n\u001b[0;32m    126\u001b[0m     \u001b[39m# validation_data=(val.sequences, val.targets),\u001b[39;49;00m\n\u001b[0;32m    127\u001b[0m     \u001b[39m# validation_batch_size=batch_size,\u001b[39;49;00m\n\u001b[0;32m    128\u001b[0m     callbacks\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mTerminateOnNaN(),\n\u001b[0;32m    129\u001b[0m )\n\u001b[0;32m    130\u001b[0m     \u001b[39m# y_pred = nnRecModel.predict(test.sequences, batch_size=batch_size)\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[39m# print('Test Accuracy: ', CustomSparseTopKCategoricalAccuracy(test.targets, y_pred))\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39mreturn\u001b[39;00m hist\n","File \u001b[1;32mc:\\Users\\Carrt\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\Carrt\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n","\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'seq_embedding' (type Embedding).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[386,20] = 1681 is not in [0, 1681) [Op:ResourceGather]\n\nCall arguments received by layer 'seq_embedding' (type Embedding):\n  • inputs=tf.Tensor(shape=(512, 100), dtype=float32)"]}],"source":["hist = test_model(model, train, validation, test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1683120889043,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"X6zgJXu50leK","outputId":"a9443fb7-584c-4e79-a596-088e9f53e340"},"outputs":[{"data":{"text/plain":["array([[2566],\n","       [  49],\n","       [3301],\n","       ...,\n","       [1537],\n","       [ 320],\n","       [1914]])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["train.targets"]},{"cell_type":"markdown","metadata":{"id":"tB6N7wq-sNNS"},"source":["### NextItNet_Vanila"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":759,"status":"ok","timestamp":1683146168302,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"an7qW21E7nVT","outputId":"c754868d-d898-43f8-9fad-6192affe8ab0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_28\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," seq_input (InputLayer)      [(None, 100)]             0         \n","                                                                 \n"," seq_embedding (Embedding)   (None, 100, 64)           107584    \n","                                                                 \n"," conv1d_105 (Conv1D)         (None, 100, 64)           12352     \n","                                                                 \n"," dropout_168 (Dropout)       (None, 100, 64)           0         \n","                                                                 \n"," conv1d_106 (Conv1D)         (None, 100, 64)           12352     \n","                                                                 \n"," dropout_169 (Dropout)       (None, 100, 64)           0         \n","                                                                 \n"," conv1d_107 (Conv1D)         (None, 100, 64)           12352     \n","                                                                 \n"," dropout_170 (Dropout)       (None, 100, 64)           0         \n","                                                                 \n"," tf.__operators__.getitem_38  (None, 64)               0         \n","  (SlicingOpLambda)                                              \n","                                                                 \n"," tf.reshape_34 (TFOpLambda)  (None, 64)                0         \n","                                                                 \n"," dropout_171 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_37 (Dense)            (None, 1681)              109265    \n","                                                                 \n"," dropout_172 (Dropout)       (None, 1681)              0         \n","                                                                 \n","=================================================================\n","Total params: 253,905\n","Trainable params: 253,905\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"data":{"image/svg+xml":["<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"451pt\" height=\"1401pt\" viewBox=\"0.00 0.00 338.00 1051.00\">\n","<g id=\"graph0\" class=\"graph\" transform=\"scale(0.75 0.75) rotate(0) translate(4 1047)\">\n","<title>G</title>\n","<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-1047 334,-1047 334,4 -4,4\"/>\n","<!-- 140630094761984 -->\n","<g id=\"node1\" class=\"node\">\n","<title>140630094761984</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"53,-996.5 53,-1042.5 277,-1042.5 277,-996.5 53,-996.5\"/>\n","<text text-anchor=\"middle\" x=\"91.5\" y=\"-1027.3\" font-family=\"Times,serif\" font-size=\"14.00\">seq_input</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"53,-1019.5 130,-1019.5 \"/>\n","<text text-anchor=\"middle\" x=\"91.5\" y=\"-1004.3\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"130,-996.5 130,-1042.5 \"/>\n","<text text-anchor=\"middle\" x=\"157.5\" y=\"-1027.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"130,-1019.5 185,-1019.5 \"/>\n","<text text-anchor=\"middle\" x=\"157.5\" y=\"-1004.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"185,-996.5 185,-1042.5 \"/>\n","<text text-anchor=\"middle\" x=\"231\" y=\"-1027.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 100)]</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"185,-1019.5 277,-1019.5 \"/>\n","<text text-anchor=\"middle\" x=\"231\" y=\"-1004.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 100)]</text>\n","</g>\n","<!-- 140630095573872 -->\n","<g id=\"node2\" class=\"node\">\n","<title>140630095573872</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"34.5,-913.5 34.5,-959.5 295.5,-959.5 295.5,-913.5 34.5,-913.5\"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-944.3\" font-family=\"Times,serif\" font-size=\"14.00\">seq_embedding</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"34.5,-936.5 136.5,-936.5 \"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-921.3\" font-family=\"Times,serif\" font-size=\"14.00\">Embedding</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"136.5,-913.5 136.5,-959.5 \"/>\n","<text text-anchor=\"middle\" x=\"164\" y=\"-944.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"136.5,-936.5 191.5,-936.5 \"/>\n","<text text-anchor=\"middle\" x=\"164\" y=\"-921.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"191.5,-913.5 191.5,-959.5 \"/>\n","<text text-anchor=\"middle\" x=\"243.5\" y=\"-944.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"191.5,-936.5 295.5,-936.5 \"/>\n","<text text-anchor=\"middle\" x=\"243.5\" y=\"-921.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","</g>\n","<!-- 140630094761984&#45;&gt;140630095573872 -->\n","<g id=\"edge1\" class=\"edge\">\n","<title>140630094761984-&gt;140630095573872</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M165,-996.37C165,-988.15 165,-978.66 165,-969.73\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-969.61 165,-959.61 161.5,-969.61 168.5,-969.61\"/>\n","</g>\n","<!-- 140630095561968 -->\n","<g id=\"node3\" class=\"node\">\n","<title>140630095561968</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"44,-830.5 44,-876.5 286,-876.5 286,-830.5 44,-830.5\"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-861.3\" font-family=\"Times,serif\" font-size=\"14.00\">conv1d_105</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"44,-853.5 127,-853.5 \"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-838.3\" font-family=\"Times,serif\" font-size=\"14.00\">Conv1D</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"127,-830.5 127,-876.5 \"/>\n","<text text-anchor=\"middle\" x=\"154.5\" y=\"-861.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"127,-853.5 182,-853.5 \"/>\n","<text text-anchor=\"middle\" x=\"154.5\" y=\"-838.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"182,-830.5 182,-876.5 \"/>\n","<text text-anchor=\"middle\" x=\"234\" y=\"-861.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"182,-853.5 286,-853.5 \"/>\n","<text text-anchor=\"middle\" x=\"234\" y=\"-838.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","</g>\n","<!-- 140630095573872&#45;&gt;140630095561968 -->\n","<g id=\"edge2\" class=\"edge\">\n","<title>140630095573872-&gt;140630095561968</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M165,-913.37C165,-905.15 165,-895.66 165,-886.73\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-886.61 165,-876.61 161.5,-886.61 168.5,-886.61\"/>\n","</g>\n","<!-- 140629714214368 -->\n","<g id=\"node4\" class=\"node\">\n","<title>140629714214368</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"42.5,-747.5 42.5,-793.5 287.5,-793.5 287.5,-747.5 42.5,-747.5\"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-778.3\" font-family=\"Times,serif\" font-size=\"14.00\">dropout_168</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"42.5,-770.5 128.5,-770.5 \"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-755.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"128.5,-747.5 128.5,-793.5 \"/>\n","<text text-anchor=\"middle\" x=\"156\" y=\"-778.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"128.5,-770.5 183.5,-770.5 \"/>\n","<text text-anchor=\"middle\" x=\"156\" y=\"-755.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"183.5,-747.5 183.5,-793.5 \"/>\n","<text text-anchor=\"middle\" x=\"235.5\" y=\"-778.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"183.5,-770.5 287.5,-770.5 \"/>\n","<text text-anchor=\"middle\" x=\"235.5\" y=\"-755.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","</g>\n","<!-- 140630095561968&#45;&gt;140629714214368 -->\n","<g id=\"edge3\" class=\"edge\">\n","<title>140630095561968-&gt;140629714214368</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M165,-830.37C165,-822.15 165,-812.66 165,-803.73\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-803.61 165,-793.61 161.5,-803.61 168.5,-803.61\"/>\n","</g>\n","<!-- 140630095571520 -->\n","<g id=\"node5\" class=\"node\">\n","<title>140630095571520</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"44,-664.5 44,-710.5 286,-710.5 286,-664.5 44,-664.5\"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-695.3\" font-family=\"Times,serif\" font-size=\"14.00\">conv1d_106</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"44,-687.5 127,-687.5 \"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-672.3\" font-family=\"Times,serif\" font-size=\"14.00\">Conv1D</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"127,-664.5 127,-710.5 \"/>\n","<text text-anchor=\"middle\" x=\"154.5\" y=\"-695.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"127,-687.5 182,-687.5 \"/>\n","<text text-anchor=\"middle\" x=\"154.5\" y=\"-672.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"182,-664.5 182,-710.5 \"/>\n","<text text-anchor=\"middle\" x=\"234\" y=\"-695.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"182,-687.5 286,-687.5 \"/>\n","<text text-anchor=\"middle\" x=\"234\" y=\"-672.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","</g>\n","<!-- 140629714214368&#45;&gt;140630095571520 -->\n","<g id=\"edge4\" class=\"edge\">\n","<title>140629714214368-&gt;140630095571520</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M165,-747.37C165,-739.15 165,-729.66 165,-720.73\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-720.61 165,-710.61 161.5,-720.61 168.5,-720.61\"/>\n","</g>\n","<!-- 140630095565952 -->\n","<g id=\"node6\" class=\"node\">\n","<title>140630095565952</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"42.5,-581.5 42.5,-627.5 287.5,-627.5 287.5,-581.5 42.5,-581.5\"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-612.3\" font-family=\"Times,serif\" font-size=\"14.00\">dropout_169</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"42.5,-604.5 128.5,-604.5 \"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-589.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"128.5,-581.5 128.5,-627.5 \"/>\n","<text text-anchor=\"middle\" x=\"156\" y=\"-612.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"128.5,-604.5 183.5,-604.5 \"/>\n","<text text-anchor=\"middle\" x=\"156\" y=\"-589.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"183.5,-581.5 183.5,-627.5 \"/>\n","<text text-anchor=\"middle\" x=\"235.5\" y=\"-612.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"183.5,-604.5 287.5,-604.5 \"/>\n","<text text-anchor=\"middle\" x=\"235.5\" y=\"-589.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","</g>\n","<!-- 140630095571520&#45;&gt;140630095565952 -->\n","<g id=\"edge5\" class=\"edge\">\n","<title>140630095571520-&gt;140630095565952</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M165,-664.37C165,-656.15 165,-646.66 165,-637.73\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-637.61 165,-627.61 161.5,-637.61 168.5,-637.61\"/>\n","</g>\n","<!-- 140630095566768 -->\n","<g id=\"node7\" class=\"node\">\n","<title>140630095566768</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"44,-498.5 44,-544.5 286,-544.5 286,-498.5 44,-498.5\"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">conv1d_107</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"44,-521.5 127,-521.5 \"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">Conv1D</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"127,-498.5 127,-544.5 \"/>\n","<text text-anchor=\"middle\" x=\"154.5\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"127,-521.5 182,-521.5 \"/>\n","<text text-anchor=\"middle\" x=\"154.5\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"182,-498.5 182,-544.5 \"/>\n","<text text-anchor=\"middle\" x=\"234\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"182,-521.5 286,-521.5 \"/>\n","<text text-anchor=\"middle\" x=\"234\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","</g>\n","<!-- 140630095565952&#45;&gt;140630095566768 -->\n","<g id=\"edge6\" class=\"edge\">\n","<title>140630095565952-&gt;140630095566768</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M165,-581.37C165,-573.15 165,-563.66 165,-554.73\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-554.61 165,-544.61 161.5,-554.61 168.5,-554.61\"/>\n","</g>\n","<!-- 140630095563312 -->\n","<g id=\"node8\" class=\"node\">\n","<title>140630095563312</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"42.5,-415.5 42.5,-461.5 287.5,-461.5 287.5,-415.5 42.5,-415.5\"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">dropout_170</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"42.5,-438.5 128.5,-438.5 \"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"128.5,-415.5 128.5,-461.5 \"/>\n","<text text-anchor=\"middle\" x=\"156\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"128.5,-438.5 183.5,-438.5 \"/>\n","<text text-anchor=\"middle\" x=\"156\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"183.5,-415.5 183.5,-461.5 \"/>\n","<text text-anchor=\"middle\" x=\"235.5\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"183.5,-438.5 287.5,-438.5 \"/>\n","<text text-anchor=\"middle\" x=\"235.5\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","</g>\n","<!-- 140630095566768&#45;&gt;140630095563312 -->\n","<g id=\"edge7\" class=\"edge\">\n","<title>140630095566768-&gt;140630095563312</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M165,-498.37C165,-490.15 165,-480.66 165,-471.73\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-471.61 165,-461.61 161.5,-471.61 168.5,-471.61\"/>\n","</g>\n","<!-- 140630095570608 -->\n","<g id=\"node9\" class=\"node\">\n","<title>140630095570608</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"0,-332.5 0,-378.5 330,-378.5 330,-332.5 0,-332.5\"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">tf.__operators__.getitem_38</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"0,-355.5 171,-355.5 \"/>\n","<text text-anchor=\"middle\" x=\"85.5\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">SlicingOpLambda</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"171,-332.5 171,-378.5 \"/>\n","<text text-anchor=\"middle\" x=\"198.5\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"171,-355.5 226,-355.5 \"/>\n","<text text-anchor=\"middle\" x=\"198.5\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"226,-332.5 226,-378.5 \"/>\n","<text text-anchor=\"middle\" x=\"278\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"226,-355.5 330,-355.5 \"/>\n","<text text-anchor=\"middle\" x=\"278\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 64)</text>\n","</g>\n","<!-- 140630095563312&#45;&gt;140630095570608 -->\n","<g id=\"edge8\" class=\"edge\">\n","<title>140630095563312-&gt;140630095570608</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M165,-415.37C165,-407.15 165,-397.66 165,-388.73\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-388.61 165,-378.61 161.5,-388.61 168.5,-388.61\"/>\n","</g>\n","<!-- 140630095571136 -->\n","<g id=\"node10\" class=\"node\">\n","<title>140630095571136</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"52.5,-249.5 52.5,-295.5 277.5,-295.5 277.5,-249.5 52.5,-249.5\"/>\n","<text text-anchor=\"middle\" x=\"99.5\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">tf.reshape_34</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"52.5,-272.5 146.5,-272.5 \"/>\n","<text text-anchor=\"middle\" x=\"99.5\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">TFOpLambda</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"146.5,-249.5 146.5,-295.5 \"/>\n","<text text-anchor=\"middle\" x=\"174\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"146.5,-272.5 201.5,-272.5 \"/>\n","<text text-anchor=\"middle\" x=\"174\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"201.5,-249.5 201.5,-295.5 \"/>\n","<text text-anchor=\"middle\" x=\"239.5\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"201.5,-272.5 277.5,-272.5 \"/>\n","<text text-anchor=\"middle\" x=\"239.5\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 64)</text>\n","</g>\n","<!-- 140630095570608&#45;&gt;140630095571136 -->\n","<g id=\"edge9\" class=\"edge\">\n","<title>140630095570608-&gt;140630095571136</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M165,-332.37C165,-324.15 165,-314.66 165,-305.73\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-305.61 165,-295.61 161.5,-305.61 168.5,-305.61\"/>\n","</g>\n","<!-- 140630095575264 -->\n","<g id=\"node11\" class=\"node\">\n","<title>140630095575264</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"56.5,-166.5 56.5,-212.5 273.5,-212.5 273.5,-166.5 56.5,-166.5\"/>\n","<text text-anchor=\"middle\" x=\"99.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">dropout_171</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"56.5,-189.5 142.5,-189.5 \"/>\n","<text text-anchor=\"middle\" x=\"99.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"142.5,-166.5 142.5,-212.5 \"/>\n","<text text-anchor=\"middle\" x=\"170\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"142.5,-189.5 197.5,-189.5 \"/>\n","<text text-anchor=\"middle\" x=\"170\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"197.5,-166.5 197.5,-212.5 \"/>\n","<text text-anchor=\"middle\" x=\"235.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"197.5,-189.5 273.5,-189.5 \"/>\n","<text text-anchor=\"middle\" x=\"235.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 64)</text>\n","</g>\n","<!-- 140630095571136&#45;&gt;140630095575264 -->\n","<g id=\"edge10\" class=\"edge\">\n","<title>140630095571136-&gt;140630095575264</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M165,-249.37C165,-241.15 165,-231.66 165,-222.73\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-222.61 165,-212.61 161.5,-222.61 168.5,-222.61\"/>\n","</g>\n","<!-- 140629713275104 -->\n","<g id=\"node12\" class=\"node\">\n","<title>140629713275104</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"59,-83.5 59,-129.5 271,-129.5 271,-83.5 59,-83.5\"/>\n","<text text-anchor=\"middle\" x=\"93\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">dense_37</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"59,-106.5 127,-106.5 \"/>\n","<text text-anchor=\"middle\" x=\"93\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"127,-83.5 127,-129.5 \"/>\n","<text text-anchor=\"middle\" x=\"154.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"127,-106.5 182,-106.5 \"/>\n","<text text-anchor=\"middle\" x=\"154.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"182,-83.5 182,-129.5 \"/>\n","<text text-anchor=\"middle\" x=\"226.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 64)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"182,-106.5 271,-106.5 \"/>\n","<text text-anchor=\"middle\" x=\"226.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1681)</text>\n","</g>\n","<!-- 140630095575264&#45;&gt;140629713275104 -->\n","<g id=\"edge11\" class=\"edge\">\n","<title>140630095575264-&gt;140629713275104</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M165,-166.37C165,-158.15 165,-148.66 165,-139.73\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-139.61 165,-129.61 161.5,-139.61 168.5,-139.61\"/>\n","</g>\n","<!-- 140630087663232 -->\n","<g id=\"node13\" class=\"node\">\n","<title>140630087663232</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"50,-0.5 50,-46.5 280,-46.5 280,-0.5 50,-0.5\"/>\n","<text text-anchor=\"middle\" x=\"93\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">dropout_172</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"50,-23.5 136,-23.5 \"/>\n","<text text-anchor=\"middle\" x=\"93\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"136,-0.5 136,-46.5 \"/>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"136,-23.5 191,-23.5 \"/>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"191,-0.5 191,-46.5 \"/>\n","<text text-anchor=\"middle\" x=\"235.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1681)</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"191,-23.5 280,-23.5 \"/>\n","<text text-anchor=\"middle\" x=\"235.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1681)</text>\n","</g>\n","<!-- 140629713275104&#45;&gt;140630087663232 -->\n","<g id=\"edge12\" class=\"edge\">\n","<title>140629713275104-&gt;140630087663232</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M165,-83.37C165,-75.15 165,-65.66 165,-56.73\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-56.61 165,-46.61 161.5,-56.61 168.5,-56.61\"/>\n","</g>\n","</g>\n","</svg>"],"text/plain":["<IPython.core.display.SVG object>"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["class NextItNet_Dropout(nnRecSys):\n","    def __init__(self, args, data):        \n","        super(NextItNet_Dropout, self).__init__(args, data)\n","        self.saved_dir = self.saved_dir + 'NextItNet_Dropout/' + args.dataset + '/'\n","        self.embed_dim = args.embed_dims                    # 256\n","        self.residual_channels = args.residual_channels     # 256\n","        self.dilations = args.dilations                     # [1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4]\n","        self.kernel_size = args.kernel_size            # 3\n","\n","    def get_model(self, drop_prob=0.25, isDropoutTraining=True):\n","        # embed_dim = 64          # 256\n","        # embed_size = 64         # 256\n","        # dilations = [1, 2, 4]   # [1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4]\n","        # residual_channels = 32  # 256\n","        # kernel_size = 3         # 3\n","\n","        seq_input = tf.keras.layers.Input(shape=(self.sequence_length,), name='seq_input')\n","\n","        # (batch_size, sequence_length, embed_dim) --> (None, 100, 64)\n","        seq_embedding = tf.keras.layers.Embedding(\n","            input_dim = self.num_items, \n","            output_dim = self.embed_dim,\n","            name='seq_embedding',\n","            embeddings_initializer='uniform',       #embeding.weight.data.uniform_(-stdv, stdv) # important initializer, stdv = np.sqrt(1. / self.item_size)\n","            embeddings_regularizer=tf.keras.regularizers.L2(0)\n","        )(seq_input) #(batch_size, seq_len, embed_dim) = (None, 100, 64)\n","        # conv_layer = tf.keras.layers.Dropout(drop_prob)(seq_embedding, training=isDropoutTraining)\n","        conv_layer=seq_embedding\n","\n","        # conv_layer = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(conv_layer) #(batch_size, seq_len, embed_dim, 1) (None, 100, 64, 1)\n","\n","\n","        for dilation in self.dilations: #[1, 2, 4]\n","\n","            conv_layer = tf.keras.layers.Conv1D(\n","                    self.residual_channels, \n","                    kernel_size=self.kernel_size,\n","                    dilation_rate=dilation, \n","                    padding='same', \n","                    activation='tanh',\n","                )(conv_layer) # (batch_size, seq_len, embed_dim, residual_channels) = (None, 100, 98, 32), (None, 100, 94, 32), (None, 100, 86, 32)\n","            conv_layer = tf.keras.layers.Dropout(drop_prob)(conv_layer, training=isDropoutTraining)\n","\n","        flatten_layer = tf.reshape(conv_layer[:, -1,], (-1, self.residual_channels)) # (batch_size, embed_dim) = (None, 32)\n","        flatten_layer = tf.keras.layers.Dropout(drop_prob)(flatten_layer, training=isDropoutTraining)\n","        \n","        variance_layer = tf.keras.layers.Dense(self.num_items, activation='softplus',name='variance')(flatten_layer)\n","\n","        fully_connected_layer = tf.keras.layers.Dense(self.num_items, activation=None)(flatten_layer) # (batch_size, num_items) = (None, 3417)\n","        fully_connected_layer = tf.keras.layers.Dropout(drop_prob)(fully_connected_layer, training=isDropoutTraining)\n","\n","        model = tf.keras.Model(\n","            inputs=seq_input,\n","            outputs=fully_connected_layer,\n","        )\n","\n","        model.compile(\n","            optimizer=tf.keras.optimizers.Adam(learning_rate=2e-3, beta_1=0.9, beta_2=0.999, clipvalue=1.0),\n","            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","            metrics=[CustomSparseTopKCategoricalAccuracy],\n","        )\n","\n","        return model\n","\n","def test_model(nnRecModel, train, val, test):\n","    max_epochs = 10\n","    verbose = 1\n","    batch_size = 512\n","    # for iteration in range(max_epochs):\n","    hist = nnRecModel.fit(train.sequences, train.targets,\n","        verbose=verbose, \n","        batch_size=batch_size,\n","        epochs=max_epochs,\n","        # validation_data=(val.sequences, val.targets),\n","        # validation_batch_size=batch_size,\n","        callbacks=tf.keras.callbacks.TerminateOnNaN(),\n","    )\n","        # y_pred = nnRecModel.predict(test.sequences, batch_size=batch_size)\n","        # print('Test Accuracy: ', CustomSparseTopKCategoricalAccuracy(test.targets, y_pred))\n","    return hist\n","\n","# model = GRU(args, data, T=100).get_model(drop_prob=0.25)\n","model = NextItNet_Dropout(args, data).get_model(drop_prob=0.25)\n","\n","# model = NextItNet_Dropout(data, T=100).get_model(drop_prob=0.25)\n","model.summary()\n","# hist = test_model(model, train, validation, test)\n","from tensorflow.keras.utils import model_to_dot\n","from IPython.display import SVG\n","SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52145,"status":"ok","timestamp":1683146222897,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":240},"id":"sMNAQ2talczx","outputId":"8bee25b0-e6d3-41a1-d560-fdddc5b3bc05"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["63/63 [==============================] - 7s 98ms/step - loss: 7.1738 - CustomSparseTopKCategoricalAccuracy: 0.0447\n","Epoch 2/10\n","63/63 [==============================] - 5s 73ms/step - loss: 6.9597 - CustomSparseTopKCategoricalAccuracy: 0.0519\n","Epoch 3/10\n","63/63 [==============================] - 5s 77ms/step - loss: 6.9014 - CustomSparseTopKCategoricalAccuracy: 0.0630\n","Epoch 4/10\n","63/63 [==============================] - 5s 87ms/step - loss: 6.7794 - CustomSparseTopKCategoricalAccuracy: 0.0870\n","Epoch 5/10\n","63/63 [==============================] - 5s 74ms/step - loss: 6.7083 - CustomSparseTopKCategoricalAccuracy: 0.0993\n","Epoch 6/10\n","63/63 [==============================] - 5s 83ms/step - loss: 6.6346 - CustomSparseTopKCategoricalAccuracy: 0.1109\n","Epoch 7/10\n","63/63 [==============================] - 5s 79ms/step - loss: 6.5913 - CustomSparseTopKCategoricalAccuracy: 0.1201\n","Epoch 8/10\n","63/63 [==============================] - 5s 75ms/step - loss: 6.5599 - CustomSparseTopKCategoricalAccuracy: 0.1260\n","Epoch 9/10\n","63/63 [==============================] - 6s 89ms/step - loss: 6.5213 - CustomSparseTopKCategoricalAccuracy: 0.1356\n","Epoch 10/10\n","63/63 [==============================] - 5s 75ms/step - loss: 6.4942 - CustomSparseTopKCategoricalAccuracy: 0.1428\n"]}],"source":["hist = test_model(model, train, validation, test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3761935,"status":"ok","timestamp":1667038611230,"user":{"displayName":"Research Group","userId":"07008499032580121461"},"user_tz":240},"id":"W7cM6usgvY1_","outputId":"22479a2d-6ff0-46c3-e507-3b2e8cb5a31a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","3456/3456 [==============================] - 471s 134ms/step - loss: 7.3997 - sparse_top_k_categorical_accuracy: 0.0509 - val_loss: 7.1325 - val_sparse_top_k_categorical_accuracy: 0.0891\n","Epoch 2/50\n","3456/3456 [==============================] - 462s 134ms/step - loss: 6.9979 - sparse_top_k_categorical_accuracy: 0.1115 - val_loss: 6.9635 - val_sparse_top_k_categorical_accuracy: 0.1205\n","Epoch 3/50\n","3456/3456 [==============================] - 461s 134ms/step - loss: 6.8737 - sparse_top_k_categorical_accuracy: 0.1299 - val_loss: 6.9133 - val_sparse_top_k_categorical_accuracy: 0.1313\n","Epoch 4/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.8105 - sparse_top_k_categorical_accuracy: 0.1408 - val_loss: 6.8841 - val_sparse_top_k_categorical_accuracy: 0.1394\n","Epoch 5/50\n","3456/3456 [==============================] - 462s 134ms/step - loss: 6.7692 - sparse_top_k_categorical_accuracy: 0.1481 - val_loss: 6.8701 - val_sparse_top_k_categorical_accuracy: 0.1432\n","Epoch 6/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.7380 - sparse_top_k_categorical_accuracy: 0.1544 - val_loss: 6.8580 - val_sparse_top_k_categorical_accuracy: 0.1475\n","Epoch 7/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.7135 - sparse_top_k_categorical_accuracy: 0.1585 - val_loss: 6.8541 - val_sparse_top_k_categorical_accuracy: 0.1504\n","Epoch 8/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.6948 - sparse_top_k_categorical_accuracy: 0.1620 - val_loss: 6.8439 - val_sparse_top_k_categorical_accuracy: 0.1529\n","Epoch 9/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.6796 - sparse_top_k_categorical_accuracy: 0.1640 - val_loss: 6.8361 - val_sparse_top_k_categorical_accuracy: 0.1541\n","Epoch 10/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.6674 - sparse_top_k_categorical_accuracy: 0.1659 - val_loss: 6.8316 - val_sparse_top_k_categorical_accuracy: 0.1556\n","Epoch 11/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.6575 - sparse_top_k_categorical_accuracy: 0.1677 - val_loss: 6.8303 - val_sparse_top_k_categorical_accuracy: 0.1566\n","Epoch 12/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.6490 - sparse_top_k_categorical_accuracy: 0.1691 - val_loss: 6.8302 - val_sparse_top_k_categorical_accuracy: 0.1574\n","Epoch 13/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.6418 - sparse_top_k_categorical_accuracy: 0.1704 - val_loss: 6.8277 - val_sparse_top_k_categorical_accuracy: 0.1578\n","Epoch 14/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.6359 - sparse_top_k_categorical_accuracy: 0.1711 - val_loss: 6.8284 - val_sparse_top_k_categorical_accuracy: 0.1585\n","Epoch 15/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.6306 - sparse_top_k_categorical_accuracy: 0.1717 - val_loss: 6.8253 - val_sparse_top_k_categorical_accuracy: 0.1584\n","Epoch 16/50\n","3456/3456 [==============================] - 463s 134ms/step - loss: 6.6261 - sparse_top_k_categorical_accuracy: 0.1729 - val_loss: 6.8231 - val_sparse_top_k_categorical_accuracy: 0.1591\n","Epoch 17/50\n","3456/3456 [==============================] - 468s 135ms/step - loss: 6.6220 - sparse_top_k_categorical_accuracy: 0.1729 - val_loss: 6.8284 - val_sparse_top_k_categorical_accuracy: 0.1598\n","Epoch 18/50\n","3456/3456 [==============================] - 467s 135ms/step - loss: 6.6184 - sparse_top_k_categorical_accuracy: 0.1735 - val_loss: 6.8238 - val_sparse_top_k_categorical_accuracy: 0.1592\n","Epoch 19/50\n","3456/3456 [==============================] - 462s 134ms/step - loss: 6.6154 - sparse_top_k_categorical_accuracy: 0.1740 - val_loss: 6.8216 - val_sparse_top_k_categorical_accuracy: 0.1597\n","Epoch 20/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.6126 - sparse_top_k_categorical_accuracy: 0.1742 - val_loss: 6.8196 - val_sparse_top_k_categorical_accuracy: 0.1598\n","Epoch 21/50\n","3456/3456 [==============================] - 462s 134ms/step - loss: 6.6101 - sparse_top_k_categorical_accuracy: 0.1745 - val_loss: 6.8235 - val_sparse_top_k_categorical_accuracy: 0.1600\n","Epoch 22/50\n","3456/3456 [==============================] - 463s 134ms/step - loss: 6.6077 - sparse_top_k_categorical_accuracy: 0.1749 - val_loss: 6.8213 - val_sparse_top_k_categorical_accuracy: 0.1605\n","Epoch 23/50\n","3456/3456 [==============================] - 463s 134ms/step - loss: 6.6055 - sparse_top_k_categorical_accuracy: 0.1752 - val_loss: 6.8222 - val_sparse_top_k_categorical_accuracy: 0.1600\n","Epoch 24/50\n","3456/3456 [==============================] - 462s 134ms/step - loss: 6.6036 - sparse_top_k_categorical_accuracy: 0.1757 - val_loss: 6.8237 - val_sparse_top_k_categorical_accuracy: 0.1600\n","Epoch 25/50\n","3456/3456 [==============================] - 463s 134ms/step - loss: 6.6017 - sparse_top_k_categorical_accuracy: 0.1756 - val_loss: 6.8223 - val_sparse_top_k_categorical_accuracy: 0.1603\n","Epoch 26/50\n","3456/3456 [==============================] - 466s 135ms/step - loss: 6.6001 - sparse_top_k_categorical_accuracy: 0.1761 - val_loss: 6.8205 - val_sparse_top_k_categorical_accuracy: 0.1601\n","Epoch 27/50\n","3456/3456 [==============================] - 462s 134ms/step - loss: 6.5986 - sparse_top_k_categorical_accuracy: 0.1762 - val_loss: 6.8271 - val_sparse_top_k_categorical_accuracy: 0.1604\n","Epoch 28/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.5970 - sparse_top_k_categorical_accuracy: 0.1765 - val_loss: 6.8202 - val_sparse_top_k_categorical_accuracy: 0.1604\n","Epoch 29/50\n","3456/3456 [==============================] - 461s 133ms/step - loss: 6.5956 - sparse_top_k_categorical_accuracy: 0.1768 - val_loss: 6.8200 - val_sparse_top_k_categorical_accuracy: 0.1608\n","Epoch 30/50\n","3456/3456 [==============================] - 462s 134ms/step - loss: 6.5943 - sparse_top_k_categorical_accuracy: 0.1768 - val_loss: 6.8215 - val_sparse_top_k_categorical_accuracy: 0.1604\n","Epoch 31/50\n","3456/3456 [==============================] - 462s 134ms/step - loss: 6.5932 - sparse_top_k_categorical_accuracy: 0.1773 - val_loss: 6.8232 - val_sparse_top_k_categorical_accuracy: 0.1611\n","Epoch 32/50\n","3456/3456 [==============================] - 462s 134ms/step - loss: 6.5921 - sparse_top_k_categorical_accuracy: 0.1770 - val_loss: 6.8210 - val_sparse_top_k_categorical_accuracy: 0.1609\n","Epoch 33/50\n","3456/3456 [==============================] - 462s 134ms/step - loss: 6.5910 - sparse_top_k_categorical_accuracy: 0.1775 - val_loss: 6.8226 - val_sparse_top_k_categorical_accuracy: 0.1607\n","Epoch 34/50\n","3456/3456 [==============================] - 462s 134ms/step - loss: 6.5900 - sparse_top_k_categorical_accuracy: 0.1776 - val_loss: 6.8206 - val_sparse_top_k_categorical_accuracy: 0.1609\n","Epoch 35/50\n","3456/3456 [==============================] - 462s 134ms/step - loss: 6.5890 - sparse_top_k_categorical_accuracy: 0.1776 - val_loss: 6.8231 - val_sparse_top_k_categorical_accuracy: 0.1609\n","Epoch 36/50\n","3456/3456 [==============================] - 467s 135ms/step - loss: 6.5882 - sparse_top_k_categorical_accuracy: 0.1780 - val_loss: 6.8220 - val_sparse_top_k_categorical_accuracy: 0.1608\n","Epoch 37/50\n","3456/3456 [==============================] - 465s 134ms/step - loss: 6.5873 - sparse_top_k_categorical_accuracy: 0.1778 - val_loss: 6.8231 - val_sparse_top_k_categorical_accuracy: 0.1608\n","Epoch 38/50\n","3456/3456 [==============================] - 463s 134ms/step - loss: 6.5865 - sparse_top_k_categorical_accuracy: 0.1781 - val_loss: 6.8214 - val_sparse_top_k_categorical_accuracy: 0.1613\n","Epoch 39/50\n","3456/3456 [==============================] - 463s 134ms/step - loss: 6.5857 - sparse_top_k_categorical_accuracy: 0.1779 - val_loss: 6.8219 - val_sparse_top_k_categorical_accuracy: 0.1614\n","Epoch 40/50\n","3456/3456 [==============================] - 465s 135ms/step - loss: 6.5850 - sparse_top_k_categorical_accuracy: 0.1783 - val_loss: 6.8212 - val_sparse_top_k_categorical_accuracy: 0.1617\n","Epoch 41/50\n","3456/3456 [==============================] - 464s 134ms/step - loss: 6.5843 - sparse_top_k_categorical_accuracy: 0.1783 - val_loss: 6.8240 - val_sparse_top_k_categorical_accuracy: 0.1610\n","Epoch 42/50\n","3456/3456 [==============================] - 464s 134ms/step - loss: 6.5836 - sparse_top_k_categorical_accuracy: 0.1783 - val_loss: 6.8223 - val_sparse_top_k_categorical_accuracy: 0.1616\n","Epoch 43/50\n","3456/3456 [==============================] - 464s 134ms/step - loss: 6.5829 - sparse_top_k_categorical_accuracy: 0.1784 - val_loss: 6.8223 - val_sparse_top_k_categorical_accuracy: 0.1611\n","Epoch 44/50\n","3456/3456 [==============================] - 464s 134ms/step - loss: 6.5823 - sparse_top_k_categorical_accuracy: 0.1787 - val_loss: 6.8208 - val_sparse_top_k_categorical_accuracy: 0.1614\n","Epoch 45/50\n","3456/3456 [==============================] - 464s 134ms/step - loss: 6.5818 - sparse_top_k_categorical_accuracy: 0.1788 - val_loss: 6.8217 - val_sparse_top_k_categorical_accuracy: 0.1614\n","Epoch 46/50\n","3456/3456 [==============================] - 463s 134ms/step - loss: 6.5812 - sparse_top_k_categorical_accuracy: 0.1788 - val_loss: 6.8223 - val_sparse_top_k_categorical_accuracy: 0.1611\n","Epoch 47/50\n","3456/3456 [==============================] - 464s 134ms/step - loss: 6.5806 - sparse_top_k_categorical_accuracy: 0.1791 - val_loss: 6.8208 - val_sparse_top_k_categorical_accuracy: 0.1613\n","Epoch 48/50\n","3456/3456 [==============================] - 463s 134ms/step - loss: 6.5801 - sparse_top_k_categorical_accuracy: 0.1792 - val_loss: 6.8243 - val_sparse_top_k_categorical_accuracy: 0.1614\n","Epoch 49/50\n","3456/3456 [==============================] - 463s 134ms/step - loss: 6.5797 - sparse_top_k_categorical_accuracy: 0.1792 - val_loss: 6.8232 - val_sparse_top_k_categorical_accuracy: 0.1616\n","Epoch 50/50\n","3456/3456 [==============================] - 463s 134ms/step - loss: 6.5791 - sparse_top_k_categorical_accuracy: 0.1791 - val_loss: 6.8210 - val_sparse_top_k_categorical_accuracy: 0.1612\n"]}],"source":["max_epochs = 50\n","verbose = 1\n","batch_size = 128\n","\n","history = model.fit(\n","        x = train_instances.sequences, \n","        y = train_instances.targets,\n","        \n","        epochs=max_epochs,\n","        verbose=verbose, \n","        batch_size=batch_size,\n","        # validation_split = 0.20,\n","        validation_data=(\n","            validation_instances.sequences, \n","            validation_instances.targets\n","        ),\n","        validation_batch_size=batch_size,\n","        # callbacks = tf.keras.callbacks.EarlyStopping(),\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":4398342,"status":"error","timestamp":1667066932495,"user":{"displayName":"Research Group","userId":"07008499032580121461"},"user_tz":240},"id":"t_h3em4EmZ7p","outputId":"63fec5f2-0e8d-49eb-c179-ee41ad49c5ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"," 28/432 [>.............................] - ETA: 3:01 - loss: 8.0029 - CustomSparseTopKCategoricalAccuracy: 0.0201"]},{"name":"stderr","output_type":"stream","text":["ERROR:tensorflow:==================================\n","Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n","<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f74b035edd0>\n","If you want to mark it as used call its \"mark_used()\" method.\n","It was originally created here:\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 4734, in <genexpr>\n","    for ta, out in zip(output_ta_t, flat_new_output))  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py\", line 245, in wrapped\n","    error_in_function=error_in_function)\n","==================================\n"]},{"name":"stdout","output_type":"stream","text":["432/432 [==============================] - 217s 503ms/step - loss: 7.4935 - CustomSparseTopKCategoricalAccuracy: 0.0400 - val_loss: 7.1666 - val_CustomSparseTopKCategoricalAccuracy: 0.0751\n","Epoch 2/50\n","432/432 [==============================] - 216s 501ms/step - loss: 6.9908 - CustomSparseTopKCategoricalAccuracy: 0.0957 - val_loss: 6.9019 - val_CustomSparseTopKCategoricalAccuracy: 0.1094\n","Epoch 3/50\n","432/432 [==============================] - 217s 502ms/step - loss: 6.7776 - CustomSparseTopKCategoricalAccuracy: 0.1237 - val_loss: 6.7484 - val_CustomSparseTopKCategoricalAccuracy: 0.1294\n","Epoch 4/50\n","432/432 [==============================] - 220s 508ms/step - loss: 6.6576 - CustomSparseTopKCategoricalAccuracy: 0.1378 - val_loss: 6.6735 - val_CustomSparseTopKCategoricalAccuracy: 0.1374\n","Epoch 5/50\n","432/432 [==============================] - 215s 497ms/step - loss: 6.5880 - CustomSparseTopKCategoricalAccuracy: 0.1453 - val_loss: 6.6307 - val_CustomSparseTopKCategoricalAccuracy: 0.1442\n","Epoch 6/50\n","432/432 [==============================] - 215s 497ms/step - loss: 6.5385 - CustomSparseTopKCategoricalAccuracy: 0.1515 - val_loss: 6.5961 - val_CustomSparseTopKCategoricalAccuracy: 0.1473\n","Epoch 7/50\n","432/432 [==============================] - 215s 497ms/step - loss: 6.4988 - CustomSparseTopKCategoricalAccuracy: 0.1558 - val_loss: 6.5657 - val_CustomSparseTopKCategoricalAccuracy: 0.1526\n","Epoch 8/50\n","432/432 [==============================] - 214s 496ms/step - loss: 6.4715 - CustomSparseTopKCategoricalAccuracy: 0.1593 - val_loss: 6.5476 - val_CustomSparseTopKCategoricalAccuracy: 0.1531\n","Epoch 9/50\n","432/432 [==============================] - 214s 496ms/step - loss: 6.4462 - CustomSparseTopKCategoricalAccuracy: 0.1623 - val_loss: 6.5306 - val_CustomSparseTopKCategoricalAccuracy: 0.1556\n","Epoch 10/50\n","432/432 [==============================] - 215s 497ms/step - loss: 6.4265 - CustomSparseTopKCategoricalAccuracy: 0.1639 - val_loss: 6.5184 - val_CustomSparseTopKCategoricalAccuracy: 0.1562\n","Epoch 11/50\n","432/432 [==============================] - 213s 494ms/step - loss: 6.4113 - CustomSparseTopKCategoricalAccuracy: 0.1661 - val_loss: 6.5069 - val_CustomSparseTopKCategoricalAccuracy: 0.1589\n","Epoch 12/50\n","432/432 [==============================] - 216s 500ms/step - loss: 6.3947 - CustomSparseTopKCategoricalAccuracy: 0.1678 - val_loss: 6.5003 - val_CustomSparseTopKCategoricalAccuracy: 0.1590\n","Epoch 13/50\n","432/432 [==============================] - 214s 494ms/step - loss: 6.3839 - CustomSparseTopKCategoricalAccuracy: 0.1685 - val_loss: 6.4854 - val_CustomSparseTopKCategoricalAccuracy: 0.1616\n","Epoch 14/50\n","432/432 [==============================] - 214s 495ms/step - loss: 6.3707 - CustomSparseTopKCategoricalAccuracy: 0.1706 - val_loss: 6.4825 - val_CustomSparseTopKCategoricalAccuracy: 0.1627\n","Epoch 15/50\n","432/432 [==============================] - 214s 496ms/step - loss: 6.3638 - CustomSparseTopKCategoricalAccuracy: 0.1720 - val_loss: 6.4784 - val_CustomSparseTopKCategoricalAccuracy: 0.1628\n","Epoch 16/50\n","432/432 [==============================] - 213s 493ms/step - loss: 6.3532 - CustomSparseTopKCategoricalAccuracy: 0.1723 - val_loss: 6.4710 - val_CustomSparseTopKCategoricalAccuracy: 0.1618\n","Epoch 17/50\n","432/432 [==============================] - 210s 487ms/step - loss: 6.3461 - CustomSparseTopKCategoricalAccuracy: 0.1732 - val_loss: 6.4717 - val_CustomSparseTopKCategoricalAccuracy: 0.1652\n","Epoch 18/50\n","432/432 [==============================] - 211s 488ms/step - loss: 6.3382 - CustomSparseTopKCategoricalAccuracy: 0.1748 - val_loss: 6.4634 - val_CustomSparseTopKCategoricalAccuracy: 0.1642\n","Epoch 19/50\n","432/432 [==============================] - 214s 494ms/step - loss: 6.3319 - CustomSparseTopKCategoricalAccuracy: 0.1752 - val_loss: 6.4595 - val_CustomSparseTopKCategoricalAccuracy: 0.1633\n","Epoch 20/50\n","432/432 [==============================] - 213s 494ms/step - loss: 6.3265 - CustomSparseTopKCategoricalAccuracy: 0.1758 - val_loss: 6.4574 - val_CustomSparseTopKCategoricalAccuracy: 0.1656\n","Epoch 21/50\n","247/432 [================>.............] - ETA: 1:21 - loss: 6.3141 - CustomSparseTopKCategoricalAccuracy: 0.1773"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-a1a58ad41a11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mvalidation_instances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         ),\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m# callbacks = tf.keras.callbacks.EarlyStopping(),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             run_step, jit_compile=True, reduce_retracing=True)\n\u001b[1;32m   1039\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1042\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \"\"\"\n\u001b[1;32m    537\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 538\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0m\u001b[1;32m    539\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     self._assert_valid_dtypes([\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    469\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m   \u001b[0;31m# This does not work with v1 TensorArrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m   if ops.executing_eagerly_outside_functions(\n\u001b[0m\u001b[1;32m    152\u001b[0m   ) or control_flow_util.EnableControlFlowV2(ops.get_default_graph()):\n\u001b[1;32m    153\u001b[0m     \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gradient_tape/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mexecuting_eagerly_outside_functions\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5979\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"executing_eagerly_outside_functions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5980\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5981\u001b[0m   \"\"\"Returns True if executing eagerly, even if inside a graph function.\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["max_epochs = 50\n","verbose = 1\n","batch_size = 1024\n","\n","hist = model.fit(\n","        x = train_instances.sequences, \n","        y = train_instances.targets,\n","        \n","        epochs=max_epochs,\n","        verbose=verbose, \n","        batch_size=batch_size,\n","        # validation_split = 0.20,\n","        validation_data=(\n","            validation_instances.sequences, \n","            validation_instances.targets\n","        ),\n","        validation_batch_size=batch_size,\n","        # callbacks = tf.keras.callbacks.EarlyStopping(),\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":881,"status":"ok","timestamp":1667052371205,"user":{"displayName":"Research Group","userId":"07008499032580121461"},"user_tz":240},"id":"QGv0Z23X-ozi","outputId":"83089954-c73d-45ec-a0d8-424bac6a1438"},"outputs":[{"name":"stdout","output_type":"stream","text":["item_embedding.shape: (None, 100, 200)\n","gru_layer.shape: (None, 100)\n","dropout_layer.shape: (None, 100)\n","fully_connected_layer.shape: (None, 32)\n","Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input (InputLayer)          [(None, 100)]             0         \n","                                                                 \n"," embedding_1 (Embedding)     (None, 100, 200)          683400    \n","                                                                 \n"," dropout_3 (Dropout)         (None, 100, 200)          0         \n","                                                                 \n"," gru_1 (GRU)                 (None, 100)               90600     \n","                                                                 \n"," dropout_4 (Dropout)         (None, 100)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                3232      \n","                                                                 \n"," dropout_5 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 3417)              112761    \n","                                                                 \n"," softmax_output (Activation)  (None, 3417)             0         \n","                                                                 \n","=================================================================\n","Total params: 889,993\n","Trainable params: 889,993\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["### Vanila GRU for Sequential Recommendation\n","\n","class GRU:\n","    def __init__(self, data=None, sequence_length=10, T=10):\n","        self.T = T\n","        if not data:\n","            self.sequence_length = sequence_length\n","            self.num_users = 6040\n","            self.num_items = 3417        # tf.keras.layers.InputLayer((28, 28, 1)),\n","        else:\n","            self.sequence_length = data.sequence_length\n","            self.num_users = data.num_users\n","            self.num_items = data.num_items + 1        # tf.keras.layers.InputLayer((28, 28, 1)),\n","    \n","    '''\n","        dropout_flag is set to True when calculating epistemic uncertainty and it is set to False for aleatoric uncertainty calculations\n","        \n","    '''\n","    def get_model(self, drop_prob = 0.5, dropout_flag=True):\n","        embed_dim = 200\n","\n","        seq_input = tf.keras.Input(shape=self.sequence_length,name='input')\n","        # item_input = tf.keras.layers.Input(shape=(1,), name='item_input')\n","\n","\n","        # dropout = tf.keras.layers.Dropout(drop_prob)(seq_input, training=dropout_flag)\n","        item_embedding = tf.keras.layers.Embedding(\n","            input_dim=self.num_items, \n","            output_dim=embed_dim, \n","            mask_zero=True)(seq_input)\n","\n","        print('item_embedding.shape:', item_embedding.shape)\n","\n","        item_embedding_dropout = tf.keras.layers.Dropout(drop_prob)(item_embedding, training=dropout_flag)\n","        gru_layer = tf.keras.layers.GRU(100)(item_embedding_dropout)\n","        print('gru_layer.shape:', gru_layer.shape)\n","\n","        gru_dropout = tf.keras.layers.Dropout(drop_prob)(gru_layer, training=dropout_flag)\n","        print('dropout_layer.shape:', gru_dropout.shape)\n","\n","        fully_connected_layer = tf.keras.layers.Dense(32, activation=tf.nn.relu)(gru_dropout)\n","        print('fully_connected_layer.shape:', fully_connected_layer.shape)\n","\n","        fully_connected_dropout = tf.keras.layers.Dropout(drop_prob)(fully_connected_layer, training=dropout_flag)\n","\n","        variance_layer = tf.keras.layers.Dense(1, activation='softplus',name='variance')(fully_connected_dropout)\n","\n","        fully_connected_layer = tf.keras.layers.Dense(self.num_items)(fully_connected_dropout)\n","        # fully_connected_dropout = tf.keras.layers.Dropout(drop_prob)(fully_connected_layer, training=dropout_flag)\n","\n","        softmax_output = tf.keras.layers.Activation(activation=tf.nn.softmax,name='softmax_output')(fully_connected_layer)\n","\n","        logits_variance = tf.keras.layers.concatenate([softmax_output, variance_layer], name='logits_variance')\n","\n","\n","        model = tf.keras.Model(inputs=seq_input, outputs=softmax_output)\n","        # model = tf.keras.Model(inputs=seq_input, outputs=[logits_variance,softmax_output])\n","\n","        model.compile(\n","            optimizer=tf.keras.optimizers.Adam(learning_rate=2e-3, decay=1e-4),\n","            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","                # 'logits_variance': bayesian_categorical_crossentropy(100, max_movieid),\n","                # 'softmax_output': 'categorical_crossentropy'\n","            # },\n","            metrics=[tf.keras.metrics.SparseTopKCategoricalAccuracy(k=20)],\n","            # loss_weights={\n","            #     # 'logits_variance': 0.5, \n","            #     'softmax_output': 1.\n","            # }\n","        )\n","        \n","        return model\n","\n","model = GRU(data, T=100).get_model()\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6226726,"status":"error","timestamp":1667061296264,"user":{"displayName":"Research Group","userId":"07008499032580121461"},"user_tz":240},"id":"0x0qkIMzDyU6","outputId":"8865c2c1-1d9d-457c-bd55-e8ff5bae6410"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","432/432 [==============================] - 280s 649ms/step - loss: 6.5768 - sparse_top_k_categorical_accuracy: 0.1517 - val_loss: 6.6560 - val_sparse_top_k_categorical_accuracy: 0.1474\n","Epoch 2/50\n","432/432 [==============================] - 277s 643ms/step - loss: 6.5562 - sparse_top_k_categorical_accuracy: 0.1552 - val_loss: 6.6445 - val_sparse_top_k_categorical_accuracy: 0.1491\n","Epoch 3/50\n","432/432 [==============================] - 278s 644ms/step - loss: 6.5428 - sparse_top_k_categorical_accuracy: 0.1567 - val_loss: 6.6313 - val_sparse_top_k_categorical_accuracy: 0.1512\n","Epoch 4/50\n","432/432 [==============================] - 275s 638ms/step - loss: 6.5267 - sparse_top_k_categorical_accuracy: 0.1591 - val_loss: 6.6247 - val_sparse_top_k_categorical_accuracy: 0.1515\n","Epoch 5/50\n","432/432 [==============================] - 275s 636ms/step - loss: 6.5142 - sparse_top_k_categorical_accuracy: 0.1602 - val_loss: 6.6070 - val_sparse_top_k_categorical_accuracy: 0.1544\n","Epoch 6/50\n","432/432 [==============================] - 279s 646ms/step - loss: 6.4999 - sparse_top_k_categorical_accuracy: 0.1616 - val_loss: 6.5992 - val_sparse_top_k_categorical_accuracy: 0.1556\n","Epoch 7/50\n","432/432 [==============================] - 281s 652ms/step - loss: 6.4910 - sparse_top_k_categorical_accuracy: 0.1634 - val_loss: 6.5874 - val_sparse_top_k_categorical_accuracy: 0.1568\n","Epoch 8/50\n","432/432 [==============================] - 283s 656ms/step - loss: 6.4793 - sparse_top_k_categorical_accuracy: 0.1639 - val_loss: 6.5765 - val_sparse_top_k_categorical_accuracy: 0.1554\n","Epoch 9/50\n","432/432 [==============================] - 280s 648ms/step - loss: 6.4687 - sparse_top_k_categorical_accuracy: 0.1652 - val_loss: 6.5705 - val_sparse_top_k_categorical_accuracy: 0.1571\n","Epoch 10/50\n","432/432 [==============================] - 278s 643ms/step - loss: 6.4552 - sparse_top_k_categorical_accuracy: 0.1660 - val_loss: 6.5670 - val_sparse_top_k_categorical_accuracy: 0.1580\n","Epoch 11/50\n","432/432 [==============================] - 278s 643ms/step - loss: 6.4452 - sparse_top_k_categorical_accuracy: 0.1676 - val_loss: 6.5574 - val_sparse_top_k_categorical_accuracy: 0.1602\n","Epoch 12/50\n","432/432 [==============================] - 279s 646ms/step - loss: 6.4362 - sparse_top_k_categorical_accuracy: 0.1687 - val_loss: 6.5528 - val_sparse_top_k_categorical_accuracy: 0.1588\n","Epoch 13/50\n","432/432 [==============================] - 278s 645ms/step - loss: 6.4296 - sparse_top_k_categorical_accuracy: 0.1692 - val_loss: 6.5511 - val_sparse_top_k_categorical_accuracy: 0.1606\n","Epoch 14/50\n","432/432 [==============================] - 280s 648ms/step - loss: 6.4213 - sparse_top_k_categorical_accuracy: 0.1699 - val_loss: 6.5426 - val_sparse_top_k_categorical_accuracy: 0.1605\n","Epoch 15/50\n","432/432 [==============================] - 278s 643ms/step - loss: 6.4153 - sparse_top_k_categorical_accuracy: 0.1706 - val_loss: 6.5357 - val_sparse_top_k_categorical_accuracy: 0.1614\n","Epoch 16/50\n","432/432 [==============================] - 277s 642ms/step - loss: 6.4067 - sparse_top_k_categorical_accuracy: 0.1717 - val_loss: 6.5343 - val_sparse_top_k_categorical_accuracy: 0.1620\n","Epoch 17/50\n","432/432 [==============================] - 278s 643ms/step - loss: 6.3990 - sparse_top_k_categorical_accuracy: 0.1714 - val_loss: 6.5310 - val_sparse_top_k_categorical_accuracy: 0.1626\n","Epoch 18/50\n","432/432 [==============================] - 278s 645ms/step - loss: 6.3938 - sparse_top_k_categorical_accuracy: 0.1726 - val_loss: 6.5242 - val_sparse_top_k_categorical_accuracy: 0.1612\n","Epoch 19/50\n","432/432 [==============================] - 277s 643ms/step - loss: 6.3884 - sparse_top_k_categorical_accuracy: 0.1733 - val_loss: 6.5189 - val_sparse_top_k_categorical_accuracy: 0.1640\n","Epoch 20/50\n","432/432 [==============================] - 275s 637ms/step - loss: 6.3804 - sparse_top_k_categorical_accuracy: 0.1734 - val_loss: 6.5184 - val_sparse_top_k_categorical_accuracy: 0.1633\n","Epoch 21/50\n","432/432 [==============================] - 274s 634ms/step - loss: 6.3787 - sparse_top_k_categorical_accuracy: 0.1744 - val_loss: 6.5135 - val_sparse_top_k_categorical_accuracy: 0.1634\n","Epoch 22/50\n","432/432 [==============================] - 277s 642ms/step - loss: 6.3736 - sparse_top_k_categorical_accuracy: 0.1751 - val_loss: 6.5086 - val_sparse_top_k_categorical_accuracy: 0.1637\n","Epoch 23/50\n","250/432 [================>.............] - ETA: 1:20 - loss: 6.3676 - sparse_top_k_categorical_accuracy: 0.1749"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-78aff2e12834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mvalidation_instances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         ),\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m# callbacks = tf.keras.callbacks.EarlyStopping(),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             run_step, jit_compile=True, reduce_retracing=True)\n\u001b[1;32m   1039\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1042\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \"\"\"\n\u001b[1;32m    537\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 538\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0m\u001b[1;32m    539\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     self._assert_valid_dtypes([\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    469\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1738\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1740\u001b[0;31m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1741\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6013\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   6014\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6015\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   6016\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6017\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["max_epochs = 50\n","verbose = 1\n","batch_size = 1024\n","\n","history = model.fit(\n","        x = train_instances.sequences, \n","        y = train_instances.targets,\n","        \n","        epochs=max_epochs,\n","        verbose=verbose, \n","        batch_size=batch_size,\n","        # validation_split = 0.20,\n","        validation_data=(\n","            validation_instances.sequences, \n","            validation_instances.targets\n","        ),\n","        validation_batch_size=batch_size,\n","        # callbacks = tf.keras.callbacks.EarlyStopping(),\n","    )"]},{"cell_type":"markdown","metadata":{"id":"Ucy2G95bOGRe"},"source":["#### Bert4Rec"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oUIcLxQAONKv"},"outputs":[],"source":["import six\n","import tensorflow as tf\n","# from codes.Models import nnRecSys\n","\n","class TransformerBlock(tf.keras.layers.Layer):\n","\n","    def __init__(self, embed_dim, n_heads, ff_dim, rate=0.1):\n","        super().__init__()\n","        # Multi-Head Attention\n","        self.att = tf.keras.layers.MultiHeadAttention(num_heads=n_heads, key_dim=embed_dim)\n","        # Feed Forward\n","        self.ffn = tf.keras.Sequential(\n","            [tf.keras.layers.Dense(ff_dim),\n","             tf.keras.layers.Activation(tf.nn.gelu),\n","             tf.keras.layers.Dense(embed_dim)])\n","        # Normalization\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        # Dropout\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","\n","    def __call__(self, inputs, training=True):\n","        # Part 1. Multi-Head Attention + Normalization + Residual\n","        attn_output = self.att(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        # Part 2. Feed Forward + Normalization + Residual\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","class Bert4Rec(nnRecSys):\n","    def __init__(self, args, data):\n","        super(Bert4Rec, self).__init__(args, data)\n","        self.saved_dir = 'results/Bert4Rec/' + args.dataset + '/'\n","        self.embed_dim = args.embed_dims  # 256\n","        self.residual_channels = args.residual_channels  # 256\n","        self.dilations = args.dilations  # [1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4]\n","        self.kernel_size = args.kernel_size  # 3\n","\n","    def get_model(self, drop_prob=0.25, isDropoutTraining=True):\n","        embed_dim = 64\n","        n_heads = 2\n","        ff_dim = 32\n","        dropout_rate = 0.1\n","        initializer_range = 0.02\n","\n","        seq_input = tf.keras.layers.Input(shape=(self.sequence_length,), name='seq_input')\n","        # embedding\n","        # embedding_output = tf.keras.layers.Embedding(self.num_items, embed_dim, input_length=self.sequence_length)(input_tensor)\n","        embedding_output = tf.keras.layers.Embedding(\n","            input_dim=self.num_items + 1,\n","            output_dim=embed_dim,\n","            name='seq_embedding',\n","            embeddings_initializer='uniform',\n","            # embeding.weight.data.uniform_(-stdv, stdv) # important initializer, stdv = np.sqrt(1. / self.item_size)\n","            embeddings_regularizer=tf.keras.regularizers.L2(0)\n","        )(seq_input)\n","        # embedding_output, embedding_table = embedding_lookup(\n","        #     input_ids=input_tensor,\n","        #     vocab_size=self.num_items,\n","        #     embedding_size=embed_dim,\n","        #     initializer_range=initializer_range,\n","        #     word_embedding_name=\"word_embeddings\",\n","        #     use_one_hot_embeddings=True)\n","        # structure\n","        logits = TransformerBlock(embed_dim, n_heads, ff_dim, dropout_rate)(embedding_output)\n","        logits = TransformerBlock(embed_dim, n_heads, ff_dim, dropout_rate)(logits)\n","        logits = TransformerBlock(embed_dim, n_heads, ff_dim, dropout_rate)(logits)\n","        # last item\n","        last = logits[:, -1, :]  # last: (batch_size, embed_dim)\n","        # first FFN layer\n","        last = tf.keras.layers.Dense(embed_dim)(last)\n","        last = tf.keras.layers.Activation(tf.nn.gelu)(last)\n","        last = tf.keras.layers.LayerNormalization(axis=-1)(last)  # last: (batch_size, embed_dim)\n","        last = tf.keras.layers.Dropout(dropout_rate)(last, training=True)\n","        # second FFN\n","        # last = tf.linalg.matmul(last, embedding_table, transpose_b=True)\n","        # output_bias = tf.Variable(tf.zeros_initializer()(shape=[self.num_items], dtype=tf.float32))\n","        # last = tf.nn.bias_add(last, output_bias)\n","        # second FFN layer\n","        last = tf.keras.layers.Dense(self.num_items)(last)\n","        last = tf.keras.layers.Activation(tf.nn.gelu)(last)\n","        last = tf.keras.layers.LayerNormalization(axis=-1)(last)  # last: (batch_size, embed_dim)\n","        last = tf.keras.layers.Dropout(dropout_rate)(last, training=True)\n","        # softmax_output = tf.keras.layers.Activation(activation=tf.nn.softmax, name='softmax_output')(last)\n","\n","        variance = tf.keras.layers.Dense(1, activation='softplus', name='variance')(last)\n","        logits_variance = tf.keras.layers.concatenate([last, variance], name='logits_variance')\n","\n","        return self.compile_model(inputs=seq_input, outputs=logits_variance)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1598,"status":"ok","timestamp":1674681114256,"user":{"displayName":"Ruhani Faiheem Rahman","userId":"07029795085736407462"},"user_tz":300},"id":"117x0EO4Qa84","outputId":"547c7bf6-9dac-4d00-fab2-f70b70d3dc0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," seq_input (InputLayer)         [(None, 100)]        0           []                               \n","                                                                                                  \n"," seq_embedding (Embedding)      (None, 100, 64)      218688      ['seq_input[0][0]']              \n","                                                                                                  \n"," multi_head_attention (MultiHea  (None, 100, 64)     33216       ['seq_embedding[0][0]',          \n"," dAttention)                                                      'seq_embedding[0][0]']          \n","                                                                                                  \n"," dropout (Dropout)              (None, 100, 64)      0           ['multi_head_attention[0][0]']   \n","                                                                                                  \n"," tf.__operators__.add (TFOpLamb  (None, 100, 64)     0           ['seq_embedding[0][0]',          \n"," da)                                                              'dropout[0][0]']                \n","                                                                                                  \n"," layer_normalization (LayerNorm  (None, 100, 64)     128         ['tf.__operators__.add[0][0]']   \n"," alization)                                                                                       \n","                                                                                                  \n"," sequential (Sequential)        (None, 100, 64)      4192        ['layer_normalization[0][0]']    \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 100, 64)      0           ['sequential[0][0]']             \n","                                                                                                  \n"," tf.__operators__.add_1 (TFOpLa  (None, 100, 64)     0           ['layer_normalization[0][0]',    \n"," mbda)                                                            'dropout_1[0][0]']              \n","                                                                                                  \n"," layer_normalization_1 (LayerNo  (None, 100, 64)     128         ['tf.__operators__.add_1[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_1 (MultiH  (None, 100, 64)     33216       ['layer_normalization_1[0][0]',  \n"," eadAttention)                                                    'layer_normalization_1[0][0]']  \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 100, 64)      0           ['multi_head_attention_1[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_2 (TFOpLa  (None, 100, 64)     0           ['layer_normalization_1[0][0]',  \n"," mbda)                                                            'dropout_2[0][0]']              \n","                                                                                                  \n"," layer_normalization_2 (LayerNo  (None, 100, 64)     128         ['tf.__operators__.add_2[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," sequential_1 (Sequential)      (None, 100, 64)      4192        ['layer_normalization_2[0][0]']  \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 100, 64)      0           ['sequential_1[0][0]']           \n","                                                                                                  \n"," tf.__operators__.add_3 (TFOpLa  (None, 100, 64)     0           ['layer_normalization_2[0][0]',  \n"," mbda)                                                            'dropout_3[0][0]']              \n","                                                                                                  \n"," layer_normalization_3 (LayerNo  (None, 100, 64)     128         ['tf.__operators__.add_3[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_2 (MultiH  (None, 100, 64)     33216       ['layer_normalization_3[0][0]',  \n"," eadAttention)                                                    'layer_normalization_3[0][0]']  \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 100, 64)      0           ['multi_head_attention_2[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_4 (TFOpLa  (None, 100, 64)     0           ['layer_normalization_3[0][0]',  \n"," mbda)                                                            'dropout_4[0][0]']              \n","                                                                                                  \n"," layer_normalization_4 (LayerNo  (None, 100, 64)     128         ['tf.__operators__.add_4[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," sequential_2 (Sequential)      (None, 100, 64)      4192        ['layer_normalization_4[0][0]']  \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 100, 64)      0           ['sequential_2[0][0]']           \n","                                                                                                  \n"," tf.__operators__.add_5 (TFOpLa  (None, 100, 64)     0           ['layer_normalization_4[0][0]',  \n"," mbda)                                                            'dropout_5[0][0]']              \n","                                                                                                  \n"," layer_normalization_5 (LayerNo  (None, 100, 64)     128         ['tf.__operators__.add_5[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.__operators__.getitem (Slic  (None, 64)          0           ['layer_normalization_5[0][0]']  \n"," ingOpLambda)                                                                                     \n","                                                                                                  \n"," dense_6 (Dense)                (None, 64)           4160        ['tf.__operators__.getitem[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," activation_3 (Activation)      (None, 64)           0           ['dense_6[0][0]']                \n","                                                                                                  \n"," layer_normalization_6 (LayerNo  (None, 64)          128         ['activation_3[0][0]']           \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 64)           0           ['layer_normalization_6[0][0]']  \n","                                                                                                  \n"," dense_7 (Dense)                (None, 3416)         222040      ['dropout_6[0][0]']              \n","                                                                                                  \n"," activation_4 (Activation)      (None, 3416)         0           ['dense_7[0][0]']                \n","                                                                                                  \n"," layer_normalization_7 (LayerNo  (None, 3416)        6832        ['activation_4[0][0]']           \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, 3416)         0           ['layer_normalization_7[0][0]']  \n","                                                                                                  \n"," variance (Dense)               (None, 1)            3417        ['dropout_7[0][0]']              \n","                                                                                                  \n"," logits_variance (Concatenate)  (None, 3417)         0           ['dropout_7[0][0]',              \n","                                                                  'variance[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 568,257\n","Trainable params: 568,257\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["model = Bert4Rec(args, data).get_model(drop_prob=0.25)\n","model.summary()\n","# test_model(model, train, validation, test)"]},{"cell_type":"markdown","metadata":{"id":"9K8H_Bm0M6uK"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0S9IGwSI3vcz"},"outputs":[],"source":["def model_train(model, train, validation, verbose=1, max_epochs=10, batch_size=512):\n","    model.fit(\n","        [train_set.sequences, train_set.users, train_set.item_samples], \n","        {\n","            'logits_variance':train_set.y_true,\n","            'sigmoid_output':train_set.y_true\n","        },\n","        # epochs=max_epochs,\n","        verbose=verbose, \n","        batch_size=batch_size,\n","        # validation_split = 0.20,\n","        validation_data=(\n","            [validation_set.sequences, validation_set.users, validation_set.item_samples], \n","            {\n","                'logits_variance':validation_set.y_true,\n","                'sigmoid_output':validation_set.y_true\n","            },\n","        ),\n","        validation_batch_size=batch_size,\n","        # callbacks = tf.keras.callbacks.EarlyStopping(),\n","    )\n","    return model\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"az-_Yx4epNfo"},"outputs":[],"source":["def predict(model, test_set, data, verbose=1):\n","    y_pred_var, y_pred = model.predict(\n","        [\n","            test_set.sequences, \n","            test_set.users, \n","            np.repeat(np.atleast_2d(np.arange(data.num_items)), test_set.users.shape[0], axis=0)\n","        ], \n","        verbose=verbose\n","    )\n","    return y_pred\n","\n","def predict_mean(model, test_set, data, verbose=1):\n","    y_pred_var, y_pred = model.predict(\n","        [\n","            test_set.sequences, \n","            test_set.users, \n","            np.repeat(np.atleast_2d(np.arange(data.num_items)), test_set.users.shape[0], axis=0)\n","        ], \n","        verbose=verbose\n","    )\n","    return y_pred\n","    # return y_pred/np.sum(y_pred, axis=1).reshape(-1, 1)\n","\n","x = []\n","def count_hit(predictions, targets, _k, hit_count):\n","    for i, k in enumerate(_k):\n","        if k == 20:\n","            x.append(len(set(predictions[-k:]).intersection(set(targets))))\n","        if len(set(predictions[-k:]).intersection(set(targets))) > 0:\n","            hit_count[i] += 1\n","\n","def calculate_hit_rate(data, test_set, y_pred):\n","    _k = [5, 10, 20, 25, 30, 50, 100]\n","    hit_count = [0] * len(_k)\n","    print(test_set.users.shape)\n","    for test_set_index, user_id in enumerate(test_set.users.squeeze()):\n","\n","        # targets = data.test.targets[user_id] + data.user_interactions[user_id][:-(data.sequence_length+data.target_length)]\n","        targets = data.test.targets[user_id]\n","        predictions = np.argsort(y_pred[test_set_index].squeeze())\n","        # rated = set(data.user_interactions[user_id][:-data.target_length])\n","        rated = set(data.user_interactions[user_id]) - set(targets)\n","        predictions = [p for p in predictions if p not in rated]\n","\n","        count_hit(predictions, targets, _k, hit_count)\n","\n","    hr = [0] * len(_k)\n","    for i, k in enumerate(_k):\n","        hr[i] = hit_count[i]/test_set.users.shape[0]\n","        # print(hit_count[i], hr[i])\n","    return hr\n","    \n","def evaluate_model(model, data, test, verbose=1, batch_size=512):\n","    y_pred = predict(model, test, data, verbose)\n","    hit_rate = calculate_hit_rate(data, test, y_pred)\n","    return hit_rate\n","\n","def evaluate_model_by_loading_weights(model_location, data, test, isDropout=False, verbose=1, batch_size=512):\n","    model = CosRec(data, T=10).get_model(isDropout)\n","    model.load_weights(model_location)\n","    return evaluate_model(model, data, test=test, verbose=verbose, batch_size=batch_size)\n","\n","## Training Model with Full Data\n","model_saved_location = '/content/drive/My Drive/RuhaniRahman/UncertaintyRecommenderSystem/results/CosRec/epistemic_uncertainty/'\n","def get_check_point_file_name(fold, epoch, folder_path='valina_full_model/'):\n","\n","    model_check_point_location = model_saved_location + folder_path + 'fold_%i_epoch_%i'%(fold, epoch)\n","    print('Model saved at:', model_check_point_location)\n","    return model_check_point_location\n","\n","\n","\n"]}],"metadata":{"colab":{"collapsed_sections":["ly0gpS-jO46U"],"machine_shape":"hm","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
